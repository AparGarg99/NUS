{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rtavs-wks4-2-Apar Garg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRNVzhoo1clG"
      },
      "source": [
        "## **1. Mount google drive**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W39GXyk1hME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13665882-a308-4da7-d870-89597a807ad2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOQ-2xS_MYHi"
      },
      "source": [
        "## **2. Import the libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoi4gWDELtek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6e6caa-a40b-4dfb-8360-84844b4aa4e9"
      },
      "source": [
        "import cv2\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print(\"Versions of key libraries\")\n",
        "print(\"---\")\n",
        "print(\"numpy:     \", np.__version__)\n",
        "print(\"opencv    :\", cv2.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versions of key libraries\n",
            "---\n",
            "numpy:      1.19.5\n",
            "opencv    : 4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaRMTv68fEIc"
      },
      "source": [
        "## **3. Setup the classes and load the MobileNet SSD**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "236fltUAeHMA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df567afa-4d86-4769-9b85-192b946516e0"
      },
      "source": [
        "classNames      = {0: 'background',\n",
        "                   1: 'aeroplane', \n",
        "                   2: 'bicycle', \n",
        "                   3: 'bird', \n",
        "                   4: 'boat',\n",
        "                   5: 'bottle', \n",
        "                   6: 'bus', \n",
        "                   7: 'car', \n",
        "                   8: 'cat', \n",
        "                   9: 'chair',\n",
        "                   10: 'cow', \n",
        "                   11: 'diningtable', \n",
        "                   12: 'dog', \n",
        "                   13: 'horse',\n",
        "                   14: 'motorbike', \n",
        "                   15: 'person', \n",
        "                   16: 'pottedplant',\n",
        "                   17: 'sheep', \n",
        "                   18: 'sofa', \n",
        "                   19: 'train', \n",
        "                   20: 'tvmonitor'}\n",
        "\n",
        "prototxt        = '/content/gdrive/MyDrive/iss/RTAVS/day4/data/MobileNetSSD_deploy.prototxt'\n",
        "caffemodel      = '/content/gdrive/MyDrive/iss/RTAVS/day4/data/MobileNetSSD_deploy.caffemodel'\n",
        "net             = cv2.dnn.readNetFromCaffe(prototxt,\n",
        "                                           caffemodel)\n",
        "\n",
        "print(\"caffemodel '\", caffemodel, \"' loaded\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caffemodel ' /content/gdrive/MyDrive/iss/RTAVS/day4/data/MobileNetSSD_deploy.caffemodel ' loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epqhx1ZmejSV"
      },
      "source": [
        "## **4. Before the analysis**\n",
        "---\n",
        "* Step 1: Specify the video to be analyzed and its output path\n",
        "* Step 2: Load the video. Check the frames per second (`int` and `round` must be applied since the output can be `float`). Check the width and height of each frame\n",
        "* Step 3: Setup the codec and video writer. Note: colab so far does not support X264 or H264 encoding, so use MJPG and thus the extension of .avi for the output. No error will occur if a codec is not supported. However, there will no video file saved. \n",
        "* Step 4: Set the threshold to determine if the identified object should be retained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd5Hqsr3eq2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d964de8-9bfb-457f-997d-db7f81e11210"
      },
      "source": [
        "                                                                                # Step 1\n",
        "videopath       = '/content/gdrive/MyDrive/iss/RTAVS/day4/data/ff7.mp4'\n",
        "outpath         = '/content/gdrive/MyDrive/iss/RTAVS/day4/colab/ssd_ff7.avi'\n",
        "\n",
        "                                                                                # Step 2\n",
        "vs              = cv2.VideoCapture(videopath)\n",
        "fps             = int(round(vs.get(cv2.CAP_PROP_FPS)))\n",
        "W               = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "H               = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "                                                                                # Step 3\n",
        "fourcc          = cv2.VideoWriter_fourcc(*\"MJPG\")    \n",
        "writer          = cv2.VideoWriter(outpath,\n",
        "                                  fourcc,\n",
        "                                  fps,\n",
        "                                  (W, H),\n",
        "                                  True)\n",
        "\n",
        "scoreThres      = 0.5                                                           # Step 4\n",
        "\n",
        "print(\"Video to be analyzed.  :\", videopath)\n",
        "print(\"Output will be saved at:\", outpath)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video to be analyzed.  : /content/gdrive/MyDrive/iss/RTAVS/day4/data/ff7.mp4\n",
            "Output will be saved at: /content/gdrive/MyDrive/iss/RTAVS/day4/colab/ssd_ff7.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P__Mxo328iRj"
      },
      "source": [
        "## **5. Run the analysis (to be completed)**\n",
        "---\n",
        "* Step 1: Setup running number `fr` for reporting of the frame being analyzed\n",
        "* Step 2: Read a frame from video stream\n",
        "* Step 3: If there is no frame left to be analyzed, exit the while loop\n",
        "* Step 4: Prepare the blob for `net`. Get the `rows` and `cols` of the blob. The shape of `blob` is `(1,3,300,300)`\n",
        "* Step 5: Perform the prediction with MobileNet SSD. The shape of `pred` is `(1,1,n,7)`, `n` is the number of objects detected.\n",
        "* Step 6: For each detected object, check its confidence score. If the score exceeds threshold, get the class and the `(x1,y1,x2,y2)` for bounding box. Re-scale the positions (relative to the size of blob, which is `(300, 300)`).\n",
        "* Step 7: Get the actual positions of the bounding box in original frame. Express the bounding box in the form of `(x,y,w,h)`.\n",
        "* Step 8: Setup the text to be displayed on the bounding box. Get the size of the text.\n",
        "* Step 9: Draw the bounding box, put up the text.\n",
        "* Step 10: Write the frame into the output\n",
        "* Step 11: Report the amount of frames analyzed\n",
        "* Step 12: After all frames are done, close the writer and release video stream (of the original video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo-shotn8zv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6c027c-be36-427e-cb40-713eada35814"
      },
      "source": [
        "fr    = 1                                                                       # Step 1\n",
        "\n",
        "while True: \n",
        "\n",
        "    (grabbed,frame) = vs.read()                                                 # Step 2\n",
        "\n",
        "    if not grabbed:                                                             # Step 3\n",
        "      break\n",
        "    \n",
        "    output = frame.copy()\n",
        "    blob = cv2.dnn.blobFromImage(image=cv2.resize(frame,(300,300)),             # Step 4\n",
        "                                scalefactor=0.007843,\n",
        "                                size=(300, 300), \n",
        "                                mean=(127.5, 127.5, 127.5), \n",
        "                                swapRB=False,\n",
        "                                crop=False)\n",
        "    \n",
        "    rows = blob.shape[2]\n",
        "    cols = blob.shape[3]\n",
        "\n",
        "    net.setInput(blob)                                                          # Step 5\n",
        "    pred = net.forward()\n",
        "\n",
        "    numOfObjects= pred.shape[2]\n",
        "\n",
        "    for i in range(numOfObjects):\n",
        "      confidence = pred[0, 0, i, 2]\n",
        "      if confidence > scoreThres: \n",
        "        classId = int(pred[0, 0, i, 1])\n",
        "        x1 = int(pred[0, 0, i, 3] * cols) \n",
        "        y1 = int(pred[0, 0, i, 4] * rows)\n",
        "        x2 = int(pred[0, 0, i, 5] * cols)\n",
        "        y2 = int(pred[0, 0, i, 6] * rows)\n",
        "        hFactor = H/300.0 \n",
        "        wFactor = W/300.0\n",
        "        \n",
        "        x1 = int(wFactor*x1) \n",
        "        y1 = int(hFactor*y1)\n",
        "        x2 = int(wFactor*x2)\n",
        "        y2 = int(hFactor*y2)\n",
        "        x = x1\n",
        "        y = y1\n",
        "        w = x2-x1\n",
        "        h = y2-y1\n",
        "\n",
        "        txtlbl = \"{} : {:.2f}\".format(classNames[classId],confidence)\n",
        "        txtsize = cv2.getTextSize(txtlbl,\n",
        "                                  cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                  0.5,\n",
        "                                  1)\n",
        "        bsize = txtsize[0]\n",
        "        bsline = txtsize[1]\n",
        "\n",
        "        cv2.rectangle(output, \n",
        "                    (x,y),\n",
        "                    (x+w,y+h),\n",
        "                    (0, 255, 0),\n",
        "                    2)\n",
        "        \n",
        "        cv2.rectangle(output, \n",
        "                    (x-1,y),\n",
        "                    (x+bsize[0],y+bsize[1]+bsline),\n",
        "                    (0, 255, 0),\n",
        "                    -1)\n",
        "        \n",
        "        cv2.putText(output,\n",
        "                    txtlbl,\n",
        "                    (x-1,y+bsize[1]),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.5,\n",
        "                    (0, 0, 0),\n",
        "                    1,\n",
        "                    cv2.LINE_AA)\n",
        "        \n",
        "    if writer is None:\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"X264\")\n",
        "      writer = cv2.VideoWriter(outpath,\n",
        "                              fourcc,\n",
        "                              fps,\n",
        "                              (W, H),\n",
        "                              True)\n",
        "\n",
        "    \n",
        "\n",
        "    writer.write(output)                                                        # Step 10\n",
        "\n",
        "    clear_output(wait=True)                                                     # Step 11\n",
        "    if fr % 10 == 0:\n",
        "      print(fr, \"of frames analyzed ...\")\n",
        "\n",
        "    fr    = fr+1\n",
        "\n",
        "                                                                                # Step 12\n",
        "print(\"Closing ...\")\n",
        "writer.release()\n",
        "vs.release()\n",
        "print(\"Done.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing ...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GfcjXTx68Qc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}