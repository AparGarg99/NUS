{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRNVzhoo1clG"
   },
   "source": [
    "## **1. Mount google drive**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5W39GXyk1hME",
    "outputId": "7e5dc85f-540b-461e-b8df-3e5bffe92951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOQ-2xS_MYHi"
   },
   "source": [
    "## **2. Import the libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoi4gWDELtek",
    "outputId": "6d8ade6b-9825-40b6-bdec-332cacd350d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions of key libraries\n",
      "---\n",
      "tensorflow: 2.6.0\n",
      "numpy:      1.19.5\n",
      "matplotlib: 3.2.2\n",
      "pandas    : 1.1.5\n",
      "librosa   : 0.8.1\n",
      "sklearn   : 0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "import librosa\n",
    "import timeit\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import wavfile\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "print(\"Versions of key libraries\")\n",
    "print(\"---\")\n",
    "print(\"tensorflow:\", tf.__version__)\n",
    "print(\"numpy:     \", np.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "print(\"pandas    :\", pd.__version__)\n",
    "print(\"librosa   :\", librosa.__version__)\n",
    "print(\"sklearn   :\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZwvCLifbBgF"
   },
   "source": [
    "## **3. Copy data.zip from google drive to local directory**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfcZin1ubRWt",
    "outputId": "3f12a947-a892-4194-c6b1-1e5f90f9ffe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy speechsub.zip from google drive to local directory ...\n",
      "Unzip speechsub.zip ...\n",
      "Unzip completes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Copy speechsub.zip from google drive to local directory ...\")\n",
    "zipSrc  = zipfile.ZipFile(\"/content/gdrive/My Drive/iss/RTAVS/audio/data/speechsub.zip\", 'r')\n",
    "\n",
    "print(\"Unzip speechsub.zip ...\")\n",
    "zipSrc.extractall(\"/content\")\n",
    "\n",
    "zipSrc.close()\n",
    "print(\"Unzip completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaRMTv68fEIc"
   },
   "source": [
    "## **4. Change working directory to /content/**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "236fltUAeHMA",
    "outputId": "6d443f17-6888-414d-f4f7-84a89f2c7100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/content/')\n",
    "print(\"Current working directory:\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGKe5-RloBpr"
   },
   "source": [
    "## **5. Setup matplotlib**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YW_wUGJcoMZz",
    "outputId": "d449c088-7cb2-444a-99af-2d95f72c6e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib setup completes.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= True\n",
    "plt.rcParams['ytick.left']      = False\n",
    "plt.rcParams['ytick.labelleft'] = False\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "print(\"Matplotlib setup completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P__Mxo328iRj"
   },
   "source": [
    "## **6. Prepare the dataset (to be completed)**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lo-shotn8zv-",
    "outputId": "78f67403-d368-4389-f92a-1190e233ccd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking progress: 23682 records\n",
      "Time taken       :  35.72 minutes\n",
      "Expected duration: 35.72 minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# type your code below\n",
    "audioPth    = 'speechsub'\n",
    "allRecords  = []\n",
    "allLabels   = []\n",
    "\n",
    "labels      = [\"go\",\n",
    "               \"stop\",\n",
    "               \"yes\", \n",
    "               \"no\", \n",
    "               \"up\", \n",
    "               \"down\", \n",
    "               \"left\", \n",
    "               \"right\", \n",
    "               \"on\", \n",
    "               \"off\"]                                                                            # Step 2\n",
    "\n",
    "totalRecords= 0\n",
    "numOfRecords= []\n",
    "for lbl in labels:\n",
    "                                                                                # Step 3\n",
    "    pth     = os.path.join(audioPth,lbl)\n",
    "    records = [f for f in os.listdir(pth) if f.endswith('.wav')]\n",
    "    \n",
    "    numOfRecords.append(len(records))                                           # Step 4\n",
    "    totalRecords    = totalRecords+len(records)\n",
    "\n",
    "\n",
    "\n",
    "resmpRate   = 8000\n",
    "inputLength = 8000\n",
    "fftSize = 512\n",
    "\n",
    "                                                                                # Step 3\n",
    "start       = timeit.default_timer()\n",
    "run         = 1\n",
    "\n",
    "for lbl in labels:\n",
    "                                                                                # Step 4\n",
    "    pth     = os.path.join(audioPth,lbl)\n",
    "    #print(pth)\n",
    "    records = [f for f in os.listdir(pth) if f.endswith('.wav')]\n",
    "\n",
    "    for rcd in records:\n",
    "        #print(rcd)                                                                        # Step 5\n",
    "        (smp,smpR)  = librosa.load(os.path.join(pth,rcd),sr=16000)\n",
    "        smp         = librosa.resample(smp,\n",
    "                                       smpR, \n",
    "                                       resmpRate) \n",
    "        smpMfcc = librosa.feature.mfcc(y=smp,sr=resmpRate,n_mfcc=32)\n",
    "        smpMfcc = sklearn.preprocessing.scale(smpMfcc,axis=1)\n",
    "                                                                              # Step 6\n",
    "        if (len(smp)==inputLength): \n",
    "          allRecords.append(smpMfcc)\n",
    "          allLabels.append(lbl)                                                                       # Step 7\n",
    "        clear_output(wait=True)\n",
    "        stop    = timeit.default_timer()\n",
    "\n",
    "        if (run/totalRecords) < 0.05:\n",
    "            timeExpected  = \"Calculating ...\"\n",
    "        else:\n",
    "            timeNow       = timeit.default_timer()\n",
    "            timeExpected  = np.round((timeNow-start)/run*totalRecords/60,2)\n",
    "\n",
    "        print(\"Checking progress:\", run ,\"records\")   \n",
    "        print(\"Time taken       : \", np.round((stop-start)/60,2), \"minutes\")\n",
    "        print(\"Expected duration:\", timeExpected, \"minutes\")\n",
    "        print('')\n",
    "\n",
    "        run     = run+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjeDbBq2vG6e",
    "outputId": "5d256d22-8af2-46d7-c6d7-5cb36736f10d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of allRecords is (21312, 32, 32) and the data type is float32\n",
      "The shape of allLabels is (21312,)\n"
     ]
    }
   ],
   "source": [
    "allRecords = np.array(allRecords)  \n",
    "allLabels = np.array(allLabels)\n",
    "print(\"The shape of allRecords is\", allRecords.shape, \"and the data type is\", allRecords.dtype)\n",
    "print(\"The shape of allLabels is\", allLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4LRb2KdAd3B"
   },
   "source": [
    "## **7. Prepare the labels**\n",
    "---\n",
    "* Step 1: Create label encoder\n",
    "* Step 2: Generate the labels\n",
    "* Step 3: Extract the mapping between numbers and labels\n",
    "* Step 4: Convert each item in `classes` to string\n",
    "* Step 5: Perform one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ivhBQ7hAk14",
    "outputId": "38f0306c-8cfd-413c-ae91-fd0831d46f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down', 'go', 'left', 'no', 'off', 'on', 'right', 'stop', 'up', 'yes']\n"
     ]
    }
   ],
   "source": [
    "le      = LabelEncoder()                                                        # Step 1\n",
    "lbls    = le.fit_transform(allLabels)                                           # Step 2\n",
    "classes = list(le.classes_)                                                     # Step 3\n",
    "classes = [str(c) for c in classes]                                             # Step 4\n",
    "lbls    = to_categorical(lbls,num_classes=len(classes))                         # Step 5\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzDTk6tyEz8O"
   },
   "source": [
    "## **8. Split the dataset into training and testing set**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5OrwYrDE6PJ",
    "outputId": "704af655-c8e0-40ba-f98c-79bc9d85567c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of trDat is (17049, 32, 32)\n",
      "The shape of vlDat is (4263, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "(trDat,\n",
    " vlDat,\n",
    " trLbl, \n",
    " vlLbl) = train_test_split(allRecords,\n",
    "                           lbls,\n",
    "                           stratify=lbls,\n",
    "                           test_size=0.2,\n",
    "                           random_state=229,\n",
    "                           shuffle=True)\n",
    " \n",
    "print(\"The shape of trDat is\", trDat.shape)\n",
    "print(\"The shape of vlDat is\", vlDat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWFGf_hjFA1L"
   },
   "source": [
    "## **9. Define deep learning model (to be completed)**\n",
    "---\n",
    "* Step 1: Set a name for the coming model (required for saving)\n",
    "* Step 2: Define the convolutional neural network model (to be completed)\n",
    "* Step 3: Create models for training and testing\n",
    "* Step 4: Display the summary of the model of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXK9w3H6FFnP",
    "outputId": "bf816273-b842-453e-b84d-e3db539b4b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 167,242\n",
      "Trainable params: 167,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelname    = 'speechRV2'                                                      # Step 1\n",
    "\n",
    "                                                                                # Step 2\n",
    "def createModel(row,col):\n",
    "    ipt = Input(shape=(row,col,1))\n",
    "    x = Conv2D(32,(3,3), padding='valid', activation='relu')(ipt)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    " \n",
    "    x = Conv2D(64,(3,3), padding='valid', activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(128,(3,3), padding='valid', activation='relu')(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(len(classes), activation='softmax')(x)\n",
    "    model = Model(ipt, x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "nrow = trDat.shape[1]\n",
    "ncol = trDat.shape[2]                                                                           # Step 3\n",
    "model       = createModel(nrow,ncol) # This is meant for training\n",
    "modelGo     = createModel(nrow,ncol) # This is used for final testing\n",
    "\n",
    "model.summary()                                                                 # Step 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8tAEGCNFMzH"
   },
   "source": [
    "## **10. Create callbacks**\n",
    "---\n",
    "* Step 1: Create a callback to save the model from an epoch when validation accuracy is the highest\n",
    "* Step 2: Create a callback to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
    "* Step 3: Put the two callbacks objects into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Yq2ekx9FS5h",
    "outputId": "beeba72b-c464-4e4c-ef5e-341c635d5422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks created:\n",
      "<keras.callbacks.ModelCheckpoint object at 0x7f154c9574d0>\n",
      "<keras.callbacks.CSVLogger object at 0x7f154c957850>\n",
      "\n",
      "Path to model: /content/gdrive/My Drive/iss/rtavs/colab/speechRV2.hdf5\n",
      "Path to log:   /content/gdrive/My Drive/iss/rtavs/colab/speechRV2.csv\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "folderpath      = '/content/gdrive/My Drive/iss/rtavs/colab/'\n",
    "filepath        = folderpath + modelname + \".hdf5\"\n",
    "checkpoint      = ModelCheckpoint(filepath, \n",
    "                                  monitor='val_accuracy', \n",
    "                                  verbose=0, \n",
    "                                  save_best_only=True, \n",
    "                                  mode='max')\n",
    "\n",
    "csv_logger      = CSVLogger(folderpath+modelname +'.csv')                       # Step 2\n",
    "callbacks_list  = [checkpoint,csv_logger]                                       # Step 3\n",
    "\n",
    "print(\"Callbacks created:\")\n",
    "print(callbacks_list[0])\n",
    "print(callbacks_list[1])\n",
    "print('')\n",
    "print(\"Path to model:\", filepath)\n",
    "print(\"Path to log:  \", folderpath+modelname+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTUa7kDfadKS"
   },
   "source": [
    "## **11. Train the deep learning model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWz269T5ag-L",
    "outputId": "6a08fbf1-a499-4ef3-95fa-676e68d0b3d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "533/533 [==============================] - 28s 51ms/step - loss: 2.1040 - accuracy: 0.1952 - val_loss: 1.2992 - val_accuracy: 0.5311\n",
      "Epoch 2/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 1.1514 - accuracy: 0.5765 - val_loss: 0.6821 - val_accuracy: 0.7640\n",
      "Epoch 3/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.8584 - accuracy: 0.6985 - val_loss: 0.5954 - val_accuracy: 0.8008\n",
      "Epoch 4/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.7357 - accuracy: 0.7453 - val_loss: 0.5260 - val_accuracy: 0.8191\n",
      "Epoch 5/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.6606 - accuracy: 0.7773 - val_loss: 0.4535 - val_accuracy: 0.8485\n",
      "Epoch 6/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.6313 - accuracy: 0.7858 - val_loss: 0.4362 - val_accuracy: 0.8515\n",
      "Epoch 7/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.5881 - accuracy: 0.8022 - val_loss: 0.4077 - val_accuracy: 0.8698\n",
      "Epoch 8/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.5599 - accuracy: 0.8128 - val_loss: 0.3761 - val_accuracy: 0.8738\n",
      "Epoch 9/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.5324 - accuracy: 0.8235 - val_loss: 0.3880 - val_accuracy: 0.8684\n",
      "Epoch 10/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.5151 - accuracy: 0.8309 - val_loss: 0.3695 - val_accuracy: 0.8776\n",
      "Epoch 11/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.5071 - accuracy: 0.8322 - val_loss: 0.3542 - val_accuracy: 0.8841\n",
      "Epoch 12/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4926 - accuracy: 0.8342 - val_loss: 0.3411 - val_accuracy: 0.8890\n",
      "Epoch 13/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4763 - accuracy: 0.8385 - val_loss: 0.3563 - val_accuracy: 0.8806\n",
      "Epoch 14/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4748 - accuracy: 0.8435 - val_loss: 0.3258 - val_accuracy: 0.8860\n",
      "Epoch 15/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4654 - accuracy: 0.8447 - val_loss: 0.3270 - val_accuracy: 0.8895\n",
      "Epoch 16/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4513 - accuracy: 0.8511 - val_loss: 0.3189 - val_accuracy: 0.8855\n",
      "Epoch 17/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4390 - accuracy: 0.8540 - val_loss: 0.3212 - val_accuracy: 0.8860\n",
      "Epoch 18/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4352 - accuracy: 0.8560 - val_loss: 0.3187 - val_accuracy: 0.8919\n",
      "Epoch 19/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4345 - accuracy: 0.8541 - val_loss: 0.3213 - val_accuracy: 0.8909\n",
      "Epoch 20/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.4236 - accuracy: 0.8601 - val_loss: 0.3044 - val_accuracy: 0.8907\n",
      "Epoch 21/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.4219 - accuracy: 0.8605 - val_loss: 0.3063 - val_accuracy: 0.8958\n",
      "Epoch 22/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4110 - accuracy: 0.8650 - val_loss: 0.3057 - val_accuracy: 0.8949\n",
      "Epoch 23/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4073 - accuracy: 0.8642 - val_loss: 0.3063 - val_accuracy: 0.8951\n",
      "Epoch 24/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.4100 - accuracy: 0.8641 - val_loss: 0.2979 - val_accuracy: 0.8947\n",
      "Epoch 25/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.4022 - accuracy: 0.8654 - val_loss: 0.3039 - val_accuracy: 0.8942\n",
      "Epoch 26/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.3883 - accuracy: 0.8701 - val_loss: 0.3196 - val_accuracy: 0.8909\n",
      "Epoch 27/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3880 - accuracy: 0.8690 - val_loss: 0.2945 - val_accuracy: 0.8949\n",
      "Epoch 28/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.3796 - accuracy: 0.8737 - val_loss: 0.2992 - val_accuracy: 0.8963\n",
      "Epoch 29/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3715 - accuracy: 0.8753 - val_loss: 0.2945 - val_accuracy: 0.9003\n",
      "Epoch 30/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3712 - accuracy: 0.8739 - val_loss: 0.2989 - val_accuracy: 0.8947\n",
      "Epoch 31/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3674 - accuracy: 0.8765 - val_loss: 0.2910 - val_accuracy: 0.8980\n",
      "Epoch 32/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.3639 - accuracy: 0.8816 - val_loss: 0.3096 - val_accuracy: 0.8991\n",
      "Epoch 33/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3643 - accuracy: 0.8782 - val_loss: 0.2803 - val_accuracy: 0.9034\n",
      "Epoch 34/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3628 - accuracy: 0.8819 - val_loss: 0.2877 - val_accuracy: 0.8977\n",
      "Epoch 35/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3509 - accuracy: 0.8818 - val_loss: 0.2968 - val_accuracy: 0.9041\n",
      "Epoch 36/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3605 - accuracy: 0.8775 - val_loss: 0.2984 - val_accuracy: 0.8980\n",
      "Epoch 37/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.3475 - accuracy: 0.8832 - val_loss: 0.2740 - val_accuracy: 0.9052\n",
      "Epoch 38/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3579 - accuracy: 0.8827 - val_loss: 0.2730 - val_accuracy: 0.9080\n",
      "Epoch 39/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3451 - accuracy: 0.8823 - val_loss: 0.2767 - val_accuracy: 0.9076\n",
      "Epoch 40/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3437 - accuracy: 0.8870 - val_loss: 0.2931 - val_accuracy: 0.8980\n",
      "Epoch 41/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3377 - accuracy: 0.8847 - val_loss: 0.2780 - val_accuracy: 0.9034\n",
      "Epoch 42/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3346 - accuracy: 0.8900 - val_loss: 0.2747 - val_accuracy: 0.9076\n",
      "Epoch 43/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3372 - accuracy: 0.8879 - val_loss: 0.2686 - val_accuracy: 0.9062\n",
      "Epoch 44/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.3349 - accuracy: 0.8874 - val_loss: 0.2764 - val_accuracy: 0.9034\n",
      "Epoch 45/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3356 - accuracy: 0.8892 - val_loss: 0.2617 - val_accuracy: 0.9141\n",
      "Epoch 46/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3202 - accuracy: 0.8927 - val_loss: 0.2764 - val_accuracy: 0.9085\n",
      "Epoch 47/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3244 - accuracy: 0.8910 - val_loss: 0.2889 - val_accuracy: 0.9057\n",
      "Epoch 48/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3212 - accuracy: 0.8930 - val_loss: 0.2662 - val_accuracy: 0.9109\n",
      "Epoch 49/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3150 - accuracy: 0.8956 - val_loss: 0.2652 - val_accuracy: 0.9059\n",
      "Epoch 50/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3168 - accuracy: 0.8927 - val_loss: 0.2704 - val_accuracy: 0.9076\n",
      "Epoch 51/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3156 - accuracy: 0.8937 - val_loss: 0.2772 - val_accuracy: 0.9055\n",
      "Epoch 52/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3284 - accuracy: 0.8904 - val_loss: 0.2762 - val_accuracy: 0.9048\n",
      "Epoch 53/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3126 - accuracy: 0.8970 - val_loss: 0.2581 - val_accuracy: 0.9125\n",
      "Epoch 54/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3061 - accuracy: 0.8982 - val_loss: 0.2744 - val_accuracy: 0.9087\n",
      "Epoch 55/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.3064 - accuracy: 0.9003 - val_loss: 0.2678 - val_accuracy: 0.9078\n",
      "Epoch 56/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2998 - accuracy: 0.9016 - val_loss: 0.2579 - val_accuracy: 0.9137\n",
      "Epoch 57/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.3053 - accuracy: 0.8976 - val_loss: 0.2635 - val_accuracy: 0.9120\n",
      "Epoch 58/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2959 - accuracy: 0.9030 - val_loss: 0.2697 - val_accuracy: 0.9102\n",
      "Epoch 59/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2936 - accuracy: 0.9022 - val_loss: 0.2740 - val_accuracy: 0.9102\n",
      "Epoch 60/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2918 - accuracy: 0.9039 - val_loss: 0.2734 - val_accuracy: 0.9045\n",
      "Epoch 61/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2929 - accuracy: 0.9019 - val_loss: 0.2640 - val_accuracy: 0.9111\n",
      "Epoch 62/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2910 - accuracy: 0.9030 - val_loss: 0.2634 - val_accuracy: 0.9116\n",
      "Epoch 63/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2931 - accuracy: 0.9033 - val_loss: 0.2665 - val_accuracy: 0.9102\n",
      "Epoch 64/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2893 - accuracy: 0.9036 - val_loss: 0.2537 - val_accuracy: 0.9139\n",
      "Epoch 65/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2820 - accuracy: 0.9066 - val_loss: 0.2571 - val_accuracy: 0.9146\n",
      "Epoch 66/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2876 - accuracy: 0.9045 - val_loss: 0.2600 - val_accuracy: 0.9069\n",
      "Epoch 67/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2784 - accuracy: 0.9068 - val_loss: 0.2605 - val_accuracy: 0.9104\n",
      "Epoch 68/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2772 - accuracy: 0.9079 - val_loss: 0.2503 - val_accuracy: 0.9139\n",
      "Epoch 69/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2842 - accuracy: 0.9054 - val_loss: 0.2610 - val_accuracy: 0.9139\n",
      "Epoch 70/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2859 - accuracy: 0.9077 - val_loss: 0.2492 - val_accuracy: 0.9146\n",
      "Epoch 71/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2825 - accuracy: 0.9064 - val_loss: 0.2450 - val_accuracy: 0.9214\n",
      "Epoch 72/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2751 - accuracy: 0.9084 - val_loss: 0.2444 - val_accuracy: 0.9188\n",
      "Epoch 73/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2739 - accuracy: 0.9079 - val_loss: 0.2533 - val_accuracy: 0.9125\n",
      "Epoch 74/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2593 - accuracy: 0.9130 - val_loss: 0.2508 - val_accuracy: 0.9158\n",
      "Epoch 75/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2711 - accuracy: 0.9121 - val_loss: 0.2538 - val_accuracy: 0.9125\n",
      "Epoch 76/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2708 - accuracy: 0.9104 - val_loss: 0.2602 - val_accuracy: 0.9148\n",
      "Epoch 77/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2765 - accuracy: 0.9096 - val_loss: 0.2407 - val_accuracy: 0.9181\n",
      "Epoch 78/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2650 - accuracy: 0.9094 - val_loss: 0.2514 - val_accuracy: 0.9198\n",
      "Epoch 79/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2750 - accuracy: 0.9118 - val_loss: 0.2577 - val_accuracy: 0.9118\n",
      "Epoch 80/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2598 - accuracy: 0.9133 - val_loss: 0.2417 - val_accuracy: 0.9153\n",
      "Epoch 81/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2563 - accuracy: 0.9141 - val_loss: 0.2837 - val_accuracy: 0.9052\n",
      "Epoch 82/250\n",
      "533/533 [==============================] - 26s 49ms/step - loss: 0.2687 - accuracy: 0.9124 - val_loss: 0.2628 - val_accuracy: 0.9160\n",
      "Epoch 83/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2583 - accuracy: 0.9140 - val_loss: 0.2516 - val_accuracy: 0.9118\n",
      "Epoch 84/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2644 - accuracy: 0.9136 - val_loss: 0.2595 - val_accuracy: 0.9153\n",
      "Epoch 85/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2610 - accuracy: 0.9131 - val_loss: 0.2664 - val_accuracy: 0.9125\n",
      "Epoch 86/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2610 - accuracy: 0.9136 - val_loss: 0.2728 - val_accuracy: 0.9062\n",
      "Epoch 87/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2522 - accuracy: 0.9152 - val_loss: 0.2651 - val_accuracy: 0.9106\n",
      "Epoch 88/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2438 - accuracy: 0.9187 - val_loss: 0.2519 - val_accuracy: 0.9127\n",
      "Epoch 89/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2584 - accuracy: 0.9158 - val_loss: 0.2555 - val_accuracy: 0.9134\n",
      "Epoch 90/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2588 - accuracy: 0.9129 - val_loss: 0.2504 - val_accuracy: 0.9158\n",
      "Epoch 91/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2571 - accuracy: 0.9142 - val_loss: 0.2511 - val_accuracy: 0.9141\n",
      "Epoch 92/250\n",
      "533/533 [==============================] - 26s 50ms/step - loss: 0.2516 - accuracy: 0.9178 - val_loss: 0.2574 - val_accuracy: 0.9137\n",
      "Epoch 93/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2451 - accuracy: 0.9187 - val_loss: 0.2558 - val_accuracy: 0.9153\n",
      "Epoch 94/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2576 - accuracy: 0.9163 - val_loss: 0.2477 - val_accuracy: 0.9146\n",
      "Epoch 95/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2417 - accuracy: 0.9193 - val_loss: 0.2524 - val_accuracy: 0.9177\n",
      "Epoch 96/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2527 - accuracy: 0.9173 - val_loss: 0.2643 - val_accuracy: 0.9106\n",
      "Epoch 97/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2564 - accuracy: 0.9175 - val_loss: 0.2646 - val_accuracy: 0.9160\n",
      "Epoch 98/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2429 - accuracy: 0.9211 - val_loss: 0.2675 - val_accuracy: 0.9132\n",
      "Epoch 99/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2444 - accuracy: 0.9202 - val_loss: 0.2578 - val_accuracy: 0.9148\n",
      "Epoch 100/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2507 - accuracy: 0.9186 - val_loss: 0.2536 - val_accuracy: 0.9132\n",
      "Epoch 101/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2393 - accuracy: 0.9213 - val_loss: 0.2658 - val_accuracy: 0.9120\n",
      "Epoch 102/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2430 - accuracy: 0.9201 - val_loss: 0.2570 - val_accuracy: 0.9144\n",
      "Epoch 103/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2474 - accuracy: 0.9179 - val_loss: 0.2658 - val_accuracy: 0.9141\n",
      "Epoch 104/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2432 - accuracy: 0.9211 - val_loss: 0.2644 - val_accuracy: 0.9123\n",
      "Epoch 105/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2333 - accuracy: 0.9258 - val_loss: 0.2627 - val_accuracy: 0.9127\n",
      "Epoch 106/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2406 - accuracy: 0.9220 - val_loss: 0.2600 - val_accuracy: 0.9102\n",
      "Epoch 107/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2456 - accuracy: 0.9197 - val_loss: 0.2529 - val_accuracy: 0.9186\n",
      "Epoch 108/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2412 - accuracy: 0.9222 - val_loss: 0.2568 - val_accuracy: 0.9153\n",
      "Epoch 109/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2366 - accuracy: 0.9206 - val_loss: 0.2716 - val_accuracy: 0.9106\n",
      "Epoch 110/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2383 - accuracy: 0.9223 - val_loss: 0.2591 - val_accuracy: 0.9158\n",
      "Epoch 111/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2392 - accuracy: 0.9218 - val_loss: 0.2628 - val_accuracy: 0.9156\n",
      "Epoch 112/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2340 - accuracy: 0.9236 - val_loss: 0.2638 - val_accuracy: 0.9113\n",
      "Epoch 113/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2445 - accuracy: 0.9215 - val_loss: 0.2585 - val_accuracy: 0.9160\n",
      "Epoch 114/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2364 - accuracy: 0.9211 - val_loss: 0.2628 - val_accuracy: 0.9156\n",
      "Epoch 115/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2381 - accuracy: 0.9235 - val_loss: 0.2679 - val_accuracy: 0.9144\n",
      "Epoch 116/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2425 - accuracy: 0.9219 - val_loss: 0.2699 - val_accuracy: 0.9118\n",
      "Epoch 117/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2294 - accuracy: 0.9241 - val_loss: 0.2708 - val_accuracy: 0.9160\n",
      "Epoch 118/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2381 - accuracy: 0.9212 - val_loss: 0.2498 - val_accuracy: 0.9172\n",
      "Epoch 119/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2363 - accuracy: 0.9232 - val_loss: 0.2554 - val_accuracy: 0.9132\n",
      "Epoch 120/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2381 - accuracy: 0.9221 - val_loss: 0.2636 - val_accuracy: 0.9179\n",
      "Epoch 121/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2337 - accuracy: 0.9237 - val_loss: 0.2582 - val_accuracy: 0.9170\n",
      "Epoch 122/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2319 - accuracy: 0.9250 - val_loss: 0.2566 - val_accuracy: 0.9188\n",
      "Epoch 123/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2220 - accuracy: 0.9241 - val_loss: 0.2751 - val_accuracy: 0.9078\n",
      "Epoch 124/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2374 - accuracy: 0.9226 - val_loss: 0.2559 - val_accuracy: 0.9160\n",
      "Epoch 125/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2289 - accuracy: 0.9243 - val_loss: 0.2659 - val_accuracy: 0.9123\n",
      "Epoch 126/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2369 - accuracy: 0.9230 - val_loss: 0.2742 - val_accuracy: 0.9092\n",
      "Epoch 127/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2336 - accuracy: 0.9240 - val_loss: 0.2623 - val_accuracy: 0.9078\n",
      "Epoch 128/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2319 - accuracy: 0.9247 - val_loss: 0.2495 - val_accuracy: 0.9165\n",
      "Epoch 129/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2279 - accuracy: 0.9281 - val_loss: 0.2496 - val_accuracy: 0.9170\n",
      "Epoch 130/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2373 - accuracy: 0.9233 - val_loss: 0.2491 - val_accuracy: 0.9158\n",
      "Epoch 131/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2221 - accuracy: 0.9288 - val_loss: 0.2525 - val_accuracy: 0.9172\n",
      "Epoch 132/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2321 - accuracy: 0.9240 - val_loss: 0.2561 - val_accuracy: 0.9209\n",
      "Epoch 133/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2365 - accuracy: 0.9269 - val_loss: 0.2522 - val_accuracy: 0.9188\n",
      "Epoch 134/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2209 - accuracy: 0.9292 - val_loss: 0.2630 - val_accuracy: 0.9123\n",
      "Epoch 135/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2261 - accuracy: 0.9281 - val_loss: 0.2569 - val_accuracy: 0.9205\n",
      "Epoch 136/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2265 - accuracy: 0.9268 - val_loss: 0.2563 - val_accuracy: 0.9163\n",
      "Epoch 137/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2236 - accuracy: 0.9253 - val_loss: 0.2487 - val_accuracy: 0.9156\n",
      "Epoch 138/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2200 - accuracy: 0.9292 - val_loss: 0.2608 - val_accuracy: 0.9141\n",
      "Epoch 139/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2199 - accuracy: 0.9289 - val_loss: 0.2610 - val_accuracy: 0.9156\n",
      "Epoch 140/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2239 - accuracy: 0.9282 - val_loss: 0.2515 - val_accuracy: 0.9186\n",
      "Epoch 141/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2280 - accuracy: 0.9277 - val_loss: 0.2556 - val_accuracy: 0.9167\n",
      "Epoch 142/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2214 - accuracy: 0.9291 - val_loss: 0.2437 - val_accuracy: 0.9221\n",
      "Epoch 143/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2133 - accuracy: 0.9274 - val_loss: 0.2498 - val_accuracy: 0.9209\n",
      "Epoch 144/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2220 - accuracy: 0.9287 - val_loss: 0.2713 - val_accuracy: 0.9137\n",
      "Epoch 145/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2223 - accuracy: 0.9283 - val_loss: 0.2626 - val_accuracy: 0.9195\n",
      "Epoch 146/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2161 - accuracy: 0.9298 - val_loss: 0.2732 - val_accuracy: 0.9120\n",
      "Epoch 147/250\n",
      "533/533 [==============================] - 27s 50ms/step - loss: 0.2186 - accuracy: 0.9297 - val_loss: 0.2638 - val_accuracy: 0.9226\n",
      "Epoch 148/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2261 - accuracy: 0.9266 - val_loss: 0.2572 - val_accuracy: 0.9177\n",
      "Epoch 149/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2193 - accuracy: 0.9291 - val_loss: 0.2516 - val_accuracy: 0.9202\n",
      "Epoch 150/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2199 - accuracy: 0.9292 - val_loss: 0.2722 - val_accuracy: 0.9132\n",
      "Epoch 151/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2295 - accuracy: 0.9267 - val_loss: 0.2701 - val_accuracy: 0.9158\n",
      "Epoch 152/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2194 - accuracy: 0.9303 - val_loss: 0.2549 - val_accuracy: 0.9158\n",
      "Epoch 153/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2234 - accuracy: 0.9285 - val_loss: 0.2694 - val_accuracy: 0.9127\n",
      "Epoch 154/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2185 - accuracy: 0.9300 - val_loss: 0.2687 - val_accuracy: 0.9134\n",
      "Epoch 155/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2190 - accuracy: 0.9290 - val_loss: 0.2581 - val_accuracy: 0.9165\n",
      "Epoch 156/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2284 - accuracy: 0.9274 - val_loss: 0.2658 - val_accuracy: 0.9146\n",
      "Epoch 157/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2133 - accuracy: 0.9307 - val_loss: 0.2645 - val_accuracy: 0.9167\n",
      "Epoch 158/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2210 - accuracy: 0.9299 - val_loss: 0.2494 - val_accuracy: 0.9205\n",
      "Epoch 159/250\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2140 - accuracy: 0.9300 - val_loss: 0.2918 - val_accuracy: 0.9141\n",
      "Epoch 160/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2149 - accuracy: 0.9308 - val_loss: 0.2601 - val_accuracy: 0.9144\n",
      "Epoch 161/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2222 - accuracy: 0.9275 - val_loss: 0.2687 - val_accuracy: 0.9174\n",
      "Epoch 162/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2267 - accuracy: 0.9269 - val_loss: 0.2568 - val_accuracy: 0.9146\n",
      "Epoch 163/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2174 - accuracy: 0.9312 - val_loss: 0.2577 - val_accuracy: 0.9214\n",
      "Epoch 164/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2178 - accuracy: 0.9287 - val_loss: 0.2557 - val_accuracy: 0.9163\n",
      "Epoch 165/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2079 - accuracy: 0.9318 - val_loss: 0.2694 - val_accuracy: 0.9165\n",
      "Epoch 166/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2168 - accuracy: 0.9321 - val_loss: 0.2528 - val_accuracy: 0.9205\n",
      "Epoch 167/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2131 - accuracy: 0.9327 - val_loss: 0.2597 - val_accuracy: 0.9202\n",
      "Epoch 168/250\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2064 - accuracy: 0.9328 - val_loss: 0.2662 - val_accuracy: 0.9172\n",
      "Epoch 169/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2215 - accuracy: 0.9302 - val_loss: 0.2644 - val_accuracy: 0.9170\n",
      "Epoch 170/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2094 - accuracy: 0.9328 - val_loss: 0.2600 - val_accuracy: 0.9172\n",
      "Epoch 171/250\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2171 - accuracy: 0.9320 - val_loss: 0.2572 - val_accuracy: 0.9193\n",
      "Epoch 172/250\n",
      "533/533 [==============================] - 29s 55ms/step - loss: 0.2137 - accuracy: 0.9314 - val_loss: 0.2505 - val_accuracy: 0.9174\n",
      "Epoch 173/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2127 - accuracy: 0.9331 - val_loss: 0.2634 - val_accuracy: 0.9151\n",
      "Epoch 174/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2054 - accuracy: 0.9344 - val_loss: 0.2766 - val_accuracy: 0.9134\n",
      "Epoch 175/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2112 - accuracy: 0.9338 - val_loss: 0.2612 - val_accuracy: 0.9184\n",
      "Epoch 176/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2043 - accuracy: 0.9346 - val_loss: 0.2826 - val_accuracy: 0.9158\n",
      "Epoch 177/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2181 - accuracy: 0.9287 - val_loss: 0.2623 - val_accuracy: 0.9174\n",
      "Epoch 178/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2113 - accuracy: 0.9314 - val_loss: 0.2612 - val_accuracy: 0.9181\n",
      "Epoch 179/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2043 - accuracy: 0.9340 - val_loss: 0.2612 - val_accuracy: 0.9172\n",
      "Epoch 180/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2204 - accuracy: 0.9290 - val_loss: 0.2759 - val_accuracy: 0.9153\n",
      "Epoch 181/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2045 - accuracy: 0.9377 - val_loss: 0.2717 - val_accuracy: 0.9167\n",
      "Epoch 182/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2157 - accuracy: 0.9286 - val_loss: 0.2687 - val_accuracy: 0.9200\n",
      "Epoch 183/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.2119 - accuracy: 0.9351 - val_loss: 0.2570 - val_accuracy: 0.9179\n",
      "Epoch 184/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2133 - accuracy: 0.9344 - val_loss: 0.2710 - val_accuracy: 0.9144\n",
      "Epoch 185/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2099 - accuracy: 0.9324 - val_loss: 0.2609 - val_accuracy: 0.9165\n",
      "Epoch 186/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2113 - accuracy: 0.9324 - val_loss: 0.2686 - val_accuracy: 0.9127\n",
      "Epoch 187/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2082 - accuracy: 0.9351 - val_loss: 0.2606 - val_accuracy: 0.9238\n",
      "Epoch 188/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2106 - accuracy: 0.9344 - val_loss: 0.2578 - val_accuracy: 0.9165\n",
      "Epoch 189/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2026 - accuracy: 0.9342 - val_loss: 0.2747 - val_accuracy: 0.9177\n",
      "Epoch 190/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2086 - accuracy: 0.9361 - val_loss: 0.2589 - val_accuracy: 0.9214\n",
      "Epoch 191/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2030 - accuracy: 0.9351 - val_loss: 0.2790 - val_accuracy: 0.9148\n",
      "Epoch 192/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2060 - accuracy: 0.9352 - val_loss: 0.2507 - val_accuracy: 0.9224\n",
      "Epoch 193/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2027 - accuracy: 0.9362 - val_loss: 0.2625 - val_accuracy: 0.9167\n",
      "Epoch 194/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2074 - accuracy: 0.9344 - val_loss: 0.2713 - val_accuracy: 0.9141\n",
      "Epoch 195/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.1993 - accuracy: 0.9358 - val_loss: 0.2621 - val_accuracy: 0.9179\n",
      "Epoch 196/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.2016 - accuracy: 0.9352 - val_loss: 0.2775 - val_accuracy: 0.9130\n",
      "Epoch 197/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2050 - accuracy: 0.9382 - val_loss: 0.2621 - val_accuracy: 0.9172\n",
      "Epoch 198/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2051 - accuracy: 0.9363 - val_loss: 0.2745 - val_accuracy: 0.9165\n",
      "Epoch 199/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2039 - accuracy: 0.9347 - val_loss: 0.2743 - val_accuracy: 0.9184\n",
      "Epoch 200/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1935 - accuracy: 0.9369 - val_loss: 0.2705 - val_accuracy: 0.9188\n",
      "Epoch 201/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2025 - accuracy: 0.9358 - val_loss: 0.2616 - val_accuracy: 0.9144\n",
      "Epoch 202/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.2016 - accuracy: 0.9377 - val_loss: 0.2608 - val_accuracy: 0.9193\n",
      "Epoch 203/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2116 - accuracy: 0.9348 - val_loss: 0.2699 - val_accuracy: 0.9148\n",
      "Epoch 204/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2059 - accuracy: 0.9347 - val_loss: 0.2668 - val_accuracy: 0.9137\n",
      "Epoch 205/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2071 - accuracy: 0.9362 - val_loss: 0.2698 - val_accuracy: 0.9188\n",
      "Epoch 206/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2078 - accuracy: 0.9355 - val_loss: 0.2618 - val_accuracy: 0.9167\n",
      "Epoch 207/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2067 - accuracy: 0.9351 - val_loss: 0.2606 - val_accuracy: 0.9148\n",
      "Epoch 208/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1976 - accuracy: 0.9378 - val_loss: 0.2686 - val_accuracy: 0.9139\n",
      "Epoch 209/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.2057 - accuracy: 0.9344 - val_loss: 0.2649 - val_accuracy: 0.9158\n",
      "Epoch 210/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2013 - accuracy: 0.9364 - val_loss: 0.2536 - val_accuracy: 0.9207\n",
      "Epoch 211/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2005 - accuracy: 0.9363 - val_loss: 0.2525 - val_accuracy: 0.9212\n",
      "Epoch 212/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.2000 - accuracy: 0.9365 - val_loss: 0.2570 - val_accuracy: 0.9188\n",
      "Epoch 213/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1961 - accuracy: 0.9388 - val_loss: 0.2591 - val_accuracy: 0.9144\n",
      "Epoch 214/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1995 - accuracy: 0.9358 - val_loss: 0.2625 - val_accuracy: 0.9207\n",
      "Epoch 215/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1996 - accuracy: 0.9368 - val_loss: 0.2640 - val_accuracy: 0.9160\n",
      "Epoch 216/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1985 - accuracy: 0.9378 - val_loss: 0.2675 - val_accuracy: 0.9160\n",
      "Epoch 217/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1878 - accuracy: 0.9402 - val_loss: 0.2534 - val_accuracy: 0.9200\n",
      "Epoch 218/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1856 - accuracy: 0.9412 - val_loss: 0.2717 - val_accuracy: 0.9195\n",
      "Epoch 219/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1882 - accuracy: 0.9419 - val_loss: 0.2857 - val_accuracy: 0.9141\n",
      "Epoch 220/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.1940 - accuracy: 0.9369 - val_loss: 0.2678 - val_accuracy: 0.9170\n",
      "Epoch 221/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1955 - accuracy: 0.9394 - val_loss: 0.2727 - val_accuracy: 0.9109\n",
      "Epoch 222/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1990 - accuracy: 0.9396 - val_loss: 0.2720 - val_accuracy: 0.9109\n",
      "Epoch 223/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1953 - accuracy: 0.9409 - val_loss: 0.2722 - val_accuracy: 0.9174\n",
      "Epoch 224/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1982 - accuracy: 0.9363 - val_loss: 0.2751 - val_accuracy: 0.9151\n",
      "Epoch 225/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1890 - accuracy: 0.9398 - val_loss: 0.2680 - val_accuracy: 0.9179\n",
      "Epoch 226/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1974 - accuracy: 0.9383 - val_loss: 0.2802 - val_accuracy: 0.9156\n",
      "Epoch 227/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1947 - accuracy: 0.9378 - val_loss: 0.2647 - val_accuracy: 0.9156\n",
      "Epoch 228/250\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.1980 - accuracy: 0.9399 - val_loss: 0.2665 - val_accuracy: 0.9212\n",
      "Epoch 229/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1977 - accuracy: 0.9391 - val_loss: 0.2692 - val_accuracy: 0.9165\n",
      "Epoch 230/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1931 - accuracy: 0.9377 - val_loss: 0.2705 - val_accuracy: 0.9146\n",
      "Epoch 231/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.1964 - accuracy: 0.9374 - val_loss: 0.2584 - val_accuracy: 0.9158\n",
      "Epoch 232/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1998 - accuracy: 0.9375 - val_loss: 0.2625 - val_accuracy: 0.9184\n",
      "Epoch 233/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1987 - accuracy: 0.9375 - val_loss: 0.2692 - val_accuracy: 0.9156\n",
      "Epoch 234/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.1949 - accuracy: 0.9379 - val_loss: 0.2609 - val_accuracy: 0.9202\n",
      "Epoch 235/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1846 - accuracy: 0.9439 - val_loss: 0.2906 - val_accuracy: 0.9167\n",
      "Epoch 236/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1850 - accuracy: 0.9428 - val_loss: 0.2771 - val_accuracy: 0.9179\n",
      "Epoch 237/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1974 - accuracy: 0.9390 - val_loss: 0.2771 - val_accuracy: 0.9127\n",
      "Epoch 238/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.1980 - accuracy: 0.9394 - val_loss: 0.2727 - val_accuracy: 0.9163\n",
      "Epoch 239/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1949 - accuracy: 0.9393 - val_loss: 0.2559 - val_accuracy: 0.9172\n",
      "Epoch 240/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1930 - accuracy: 0.9385 - val_loss: 0.2653 - val_accuracy: 0.9170\n",
      "Epoch 241/250\n",
      "533/533 [==============================] - 27s 52ms/step - loss: 0.1954 - accuracy: 0.9408 - val_loss: 0.2612 - val_accuracy: 0.9209\n",
      "Epoch 242/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.2014 - accuracy: 0.9398 - val_loss: 0.2624 - val_accuracy: 0.9172\n",
      "Epoch 243/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1925 - accuracy: 0.9399 - val_loss: 0.2725 - val_accuracy: 0.9181\n",
      "Epoch 244/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1993 - accuracy: 0.9368 - val_loss: 0.2709 - val_accuracy: 0.9202\n",
      "Epoch 245/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1905 - accuracy: 0.9377 - val_loss: 0.2729 - val_accuracy: 0.9160\n",
      "Epoch 246/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1950 - accuracy: 0.9394 - val_loss: 0.2601 - val_accuracy: 0.9179\n",
      "Epoch 247/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1931 - accuracy: 0.9403 - val_loss: 0.2694 - val_accuracy: 0.9177\n",
      "Epoch 248/250\n",
      "533/533 [==============================] - 27s 51ms/step - loss: 0.1860 - accuracy: 0.9429 - val_loss: 0.2860 - val_accuracy: 0.9156\n",
      "Epoch 249/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1967 - accuracy: 0.9382 - val_loss: 0.2779 - val_accuracy: 0.9127\n",
      "Epoch 250/250\n",
      "533/533 [==============================] - 28s 52ms/step - loss: 0.1852 - accuracy: 0.9425 - val_loss: 0.3009 - val_accuracy: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f154c957510>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trDat, \n",
    "          trLbl, \n",
    "          validation_data=(vlDat, vlLbl), \n",
    "          epochs=250, \n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0FHohmSa5V-"
   },
   "source": [
    "## **12. Validate the deep learning model**\n",
    "---\n",
    "* Step 1: Load the trained weights and compile the model\n",
    "* Step 2: Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "879Jj4b4a6zq",
    "outputId": "fda26bbe-05bf-41f1-e689-f8cbee006387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction completes.\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "modelGo.load_weights(filepath)\n",
    "modelGo.compile(loss='categorical_crossentropy', \n",
    "                optimizer='adam', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "predicts    = modelGo.predict(vlDat)                                            # Step 2\n",
    "print(\"Prediction completes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NpnAoMSbPUl"
   },
   "source": [
    "## **13. Report classification metrics**\n",
    "---\n",
    "* Step 1: Convert label from one-hot to integer\n",
    "* Step 2: Calculate the accuracy score\n",
    "* Step 3: Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNMXgWhfbTRA",
    "outputId": "dc5708c6-136e-4678-9408-7f85b54ef769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy (on testing dataset): 92.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.9550    0.9372    0.9460       430\n",
      "          go     0.8899    0.9048    0.8973       420\n",
      "        left     0.9372    0.9307    0.9340       433\n",
      "          no     0.9320    0.8810    0.9058       420\n",
      "         off     0.8839    0.8695    0.8766       429\n",
      "          on     0.9132    0.9501    0.9313       421\n",
      "       right     0.9626    0.9559    0.9593       431\n",
      "        stop     0.9310    0.9609    0.9457       435\n",
      "          up     0.8687    0.8835    0.8761       412\n",
      "         yes     0.9629    0.9606    0.9618       432\n",
      "\n",
      "    accuracy                         0.9238      4263\n",
      "   macro avg     0.9236    0.9234    0.9234      4263\n",
      "weighted avg     0.9240    0.9238    0.9237      4263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "                                                                                # Step 1\n",
    "predout     = np.argmax(predicts,axis=1)\n",
    "testout     = np.argmax(vlLbl,axis=1)\n",
    "\n",
    "testScores  = metrics.accuracy_score(testout,predout)                           # Step 2\n",
    "\n",
    "                                                                                # Step 3\n",
    "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
    "print(metrics.classification_report(testout,\n",
    "                                    predout,\n",
    "                                    target_names=classes,\n",
    "                                    digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg-5uaMFbdFy"
   },
   "source": [
    "## **14. Print confusion matrix**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjMtQtZcbf1P",
    "outputId": "dd730617-0d9a-4e4b-b4d0-a78a1c79d00e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[403   7   1   6   0   5   0   2   5   1]\n",
      " [  7 380   1  14   5   3   1   2   4   3]\n",
      " [  1   0 403   0   3   1   9   3   4   9]\n",
      " [  6  29   4 370   2   0   1   4   3   1]\n",
      " [  1   3   3   3 373  16   3   3  24   0]\n",
      " [  0   2   3   0  10 400   0   0   5   1]\n",
      " [  1   2   5   0   2   6 412   1   2   0]\n",
      " [  1   2   1   2   5   2   0 418   4   0]\n",
      " [  0   0   5   1  21   5   1  14 364   1]\n",
      " [  2   2   4   1   1   0   1   2   4 415]]\n"
     ]
    }
   ],
   "source": [
    "confusion   = metrics.confusion_matrix(testout,predout)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2q9lWqwbkhe"
   },
   "source": [
    "## **15. Plot curves on validation loss and accuracy**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "P-xmexFDbnLo",
    "outputId": "6779ed27-7123-44e2-d96a-a7f1e0f2e855"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "records     = pd.read_csv(folderpath+modelname +'.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.50,1.00,1.50])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_accuracy'],label=\"validation\")\n",
    "plt.plot(records['accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAAQ4qBDb8y6"
   },
   "source": [
    "## **16. Save the model plot**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4nf2DuCcAc3",
    "outputId": "41cec271-8727-4cba-f25e-4f5dec1e3cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to plot: /content/gdrive/My Drive/iss/rtavs/colab/speechRV2_plot.png\n"
     ]
    }
   ],
   "source": [
    "plotpath  = folderpath+modelname+'_plot.png'\n",
    "plot_model(model, \n",
    "           to_file=plotpath, \n",
    "           show_shapes=True, \n",
    "           show_layer_names=False,\n",
    "           rankdir='TB')\n",
    "\n",
    "print(\"Path to plot:\", plotpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxLGv2q61bwp"
   },
   "source": [
    "## **17. Create a function to make prediction on a wavefile**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4lLdpE51hiK",
    "outputId": "d4bd91a4-6d88-48eb-87de-5c2c2582b618"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The command predicted from '/content/gdrive/My Drive/iss/RTAVS/audio/data/voice01.wav' is 'right'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:173: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:190: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "def commandPred(file):\n",
    "    (smp,smpR)  = librosa.load(file,sr=16000)\n",
    "    smpMfcc     = librosa.feature.mfcc(y=smp,\n",
    "                                       sr=16000,\n",
    "                                       n_mfcc=32)\n",
    "    smpMfcc     = sklearn.preprocessing.scale(smpMfcc,axis=1)\n",
    "                                                 # The output size is (32,32)                                       \n",
    "\n",
    "    smpMfcc     = np.expand_dims(smpMfcc,axis=0) # The output size is (1,32,32)\n",
    "    smpMfcc     = np.expand_dims(smpMfcc,axis=3) # The output size is (1,32,32,1)\n",
    "    pred        = modelGo.predict(smpMfcc)\n",
    "    pred        = np.argmax(pred,axis=1)\n",
    "    \n",
    "    return classes[pred[0]]\n",
    "\n",
    "\n",
    "# ............................................................................\n",
    "    \n",
    "wfile       = '/content/gdrive/My Drive/iss/RTAVS/audio/data/voice01.wav'\n",
    "pred        = commandPred(wfile)\n",
    "print(\"The command predicted from '%s' is '%s'.\" % (wfile,pred) )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rtavs-wks3-4-_Gopan_Ravikumar_Girija_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
