{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prumls_wks4_2__Apar_Garg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRNVzhoo1clG"
      },
      "source": [
        "## **1. Mount google drive**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W39GXyk1hME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff37cac8-9d1f-47d1-af98-ba50d5e0c701"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOQ-2xS_MYHi"
      },
      "source": [
        "## **2. Import the necessary libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoi4gWDELtek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c949c70-14cb-4856-a510-8808cb15684c"
      },
      "source": [
        "import matplotlib\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,LearningRateScheduler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "print(\"Versions of key libraries\")\n",
        "print(\"---\")\n",
        "print(\"tensorflow: \", tf.__version__)\n",
        "print(\"numpy:      \", np.__version__)\n",
        "print(\"matplotlib: \", matplotlib.__version__)\n",
        "print(\"sklearn:    \", sklearn.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Versions of key libraries\n",
            "---\n",
            "tensorflow:  2.5.0\n",
            "numpy:       1.19.5\n",
            "matplotlib:  3.2.2\n",
            "sklearn:     0.22.2.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0amhwjZ4M2m-"
      },
      "source": [
        "## **3.Create a function to plot image without axis**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFxsBB1mNXl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab5110ec-792e-432e-c27a-9297e2d29b17"
      },
      "source": [
        "def implt(img):\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "print(implt)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function implt at 0x7f515b2b9b00>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3N41iixORPz"
      },
      "source": [
        "## **4. Set matplotlib to have seaborn plot style**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyO5OsUrOYNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b404f14-0e66-43a7-f308-269b689dd9a3"
      },
      "source": [
        "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
        "plt.rcParams['ytick.right']     = True\n",
        "plt.rcParams['ytick.labelright']= True\n",
        "plt.rcParams['ytick.left']      = False\n",
        "plt.rcParams['ytick.labelleft'] = False\n",
        "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
        "\n",
        "print(\"Matplotlib setup completes.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matplotlib setup completes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w2jAiKZOmgP"
      },
      "source": [
        "## **5. Prepare Cifar10 data for training and testing**\n",
        "---\n",
        "* Step 1: Load the cifar10 \n",
        "* Step 2: Check the shape and type of the data\n",
        "* Step 3: Convert the data into float32 and rescale the values from the range of 0\\~255 into 0\\~1\n",
        "* Step 4: Retrieve the row size and the column size of each image\n",
        "* Step 5: Perform one-hot enconding on the labels\n",
        "* Step 6: Retrieve the number of classes in this problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Ad2V0pO1TX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45851cc3-16aa-47d4-cc87-23a0e7ece27b"
      },
      "source": [
        "                                                                                # Step 1\n",
        "data            = cifar10.load_data()\n",
        "(trDat, trLbl)  = data[0]\n",
        "(tsDat, tsLbl)  = data[1]\n",
        "\n",
        "                                                                                # Step 2\n",
        "print(\"The shape of trDat is\", trDat.shape, \"and the type of trDat is\", trDat.dtype)\n",
        "print(\"The shape of tsDat is\", tsDat.shape, \"and the type of tsDat is\", tsDat.dtype)\n",
        "print(\"\")\n",
        "print(\"The shape of trLbl is\", trLbl.shape, \"and the type of trLbl is\", trLbl.dtype)\n",
        "print(\"The shape of tsLbl is\", tsLbl.shape, \"and the type of tsLbl is\", tsLbl.dtype)\n",
        "\n",
        "                                                                                # Step 3\n",
        "trDat           = trDat.astype('float32')/255\n",
        "tsDat           = tsDat.astype('float32')/255\n",
        "\n",
        "                                                                                # Step 4\n",
        "imgrows         = trDat.shape[1]\n",
        "imgclms         = trDat.shape[2]\n",
        "channel         = trDat.shape[3]\n",
        "\n",
        "                                                                                # Step 5\n",
        "trLbl           = to_categorical(trLbl)\n",
        "tsLbl           = to_categorical(tsLbl)\n",
        "                               \n",
        "num_classes     = tsLbl.shape[1]                                                # Step 6"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 5s 0us/step\n",
            "The shape of trDat is (50000, 32, 32, 3) and the type of trDat is uint8\n",
            "The shape of tsDat is (10000, 32, 32, 3) and the type of tsDat is uint8\n",
            "\n",
            "The shape of trLbl is (50000, 1) and the type of trLbl is uint8\n",
            "The shape of tsLbl is (10000, 1) and the type of tsLbl is uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoP3WcoJW-jZ"
      },
      "source": [
        "## **6. Define the resnet model (to be completed)**\n",
        "___\n",
        "* Step 1: Setup the optimizer to be used for training\n",
        "* Step 2: Set a name for the coming model (required for saving)\n",
        "* Step 3: Function to create layers for the resnet\n",
        "* Step 4: Function to create residual blocks\n",
        "* Step 5: Define the resnet model (to be completed)\n",
        "* Step 6: Create models for training and testing\n",
        "* Step 7: Display the summary of the model of interest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HMOes0kXCPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c07ad1-d2b0-448c-a24f-742a0ec2e7d5"
      },
      "source": [
        "optmz       = optimizers.Adam(lr=0.001)                                         # Step 1\n",
        "modelname   = 'cifar10ResV1Cfg5'                                                # Step 2\n",
        "\n",
        "                                                                                # Step 3\n",
        "def resLyr(inputs,\n",
        "           numFilters=16,\n",
        "           kernelSz=3,\n",
        "           strides=1,\n",
        "           activation='relu',\n",
        "           batchNorm=True,\n",
        "           convFirst=True,\n",
        "           lyrName=None):\n",
        "\n",
        "    convLyr     = Conv2D(numFilters,\n",
        "                         kernel_size=kernelSz,\n",
        "                         strides=strides,\n",
        "                         padding='same',\n",
        "                         kernel_initializer='he_normal',\n",
        "                         kernel_regularizer=l2(1e-4),\n",
        "                         name=lyrName+'_conv' if lyrName else None)\n",
        "    x           = inputs\n",
        "    \n",
        "    if convFirst:\n",
        "        x       = convLyr(x)\n",
        "        \n",
        "        if batchNorm:\n",
        "            x   = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
        "            \n",
        "        if activation is not None:\n",
        "            x   = Activation(activation,\n",
        "                             name=lyrName+'_'+activation if lyrName else None)(x)\n",
        "    else:\n",
        "        if batchNorm:\n",
        "            x   = BatchNormalization(name=lyrName+'_bn' if lyrName else None)(x)\n",
        "            \n",
        "        if activation is not None:\n",
        "            x   = Activation(activation,\n",
        "                             name=lyrName+'_'+activation if lyrName else None)(x)\n",
        "            \n",
        "        x       = convLyr(x)\n",
        "    return x\n",
        "\n",
        "                                                                                # Step 4\n",
        "def resBlkV1(inputs,\n",
        "             numFilters=16,\n",
        "             numBlocks=3,\n",
        "             downsampleOnFirst=True,\n",
        "             names=None):\n",
        "    \n",
        "    x       = inputs\n",
        "    \n",
        "    for run in range(0,numBlocks):\n",
        "        strides = 1\n",
        "        blkStr  = str(run+1)\n",
        "        \n",
        "        if downsampleOnFirst and run == 0:\n",
        "            strides     = 2\n",
        "            \n",
        "        y       = resLyr(inputs=x,\n",
        "                         numFilters=numFilters,\n",
        "                         strides=strides,\n",
        "                         lyrName=names+'_Blk'+blkStr+'_Res1' if names else None)\n",
        "        y       = resLyr(inputs=y,\n",
        "                         numFilters=numFilters,\n",
        "                         activation=None,\n",
        "                         lyrName=names+'_Blk'+blkStr+'_Res2' if names else None)\n",
        "        \n",
        "        if downsampleOnFirst and run == 0:\n",
        "            x   = resLyr(inputs=x,\n",
        "                         numFilters=numFilters,\n",
        "                         kernelSz=1,\n",
        "                         strides=strides,\n",
        "                         activation=None,\n",
        "                         batchNorm=False,\n",
        "                         lyrName=names+'_Blk'+blkStr+'_lin' if names else None)\n",
        "\n",
        "        x       = add([x,y],\n",
        "                      name=names+'_Blk'+blkStr+'_add' if names else None)\n",
        "        x       = Activation('relu',\n",
        "                             name=names+'_Blk'+blkStr+'_relu' if names else None)(x)\n",
        "        \n",
        "    return x\n",
        "    \n",
        "                                                                                # Step 5\n",
        "def createResNetV1(inputShape=(32,32,3),numClasses=10):\n",
        "  \n",
        "  inputs = Input(shape=inputShape)\n",
        "\n",
        "  v = resLyr(inputs,lyrName='Inpt')\n",
        "\n",
        "  v = resBlkV1(inputs=v,numFilters=16,numBlocks=3,downsampleOnFirst=False,names='Stg1')\n",
        "\n",
        "  v = resBlkV1(inputs=v,numFilters=32,numBlocks=3,downsampleOnFirst=True,names='Stg2')\n",
        "\n",
        "  v = resBlkV1(inputs=v,numFilters=64,numBlocks=3,downsampleOnFirst=True,names='Stg3')\n",
        "\n",
        "\n",
        "  v = AveragePooling2D(pool_size=8,name='AvgPool')(v)\n",
        "\n",
        "  v = Flatten()(v)\n",
        "\n",
        "  outputs = Dense(numClasses,activation='softmax',kernel_initializer='he_normal')(v)\n",
        "\n",
        "  model = Model(inputs=inputs,outputs=outputs)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=optmz,metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "                                                                                # Step 6\n",
        "model       = createResNetV1()  # This is meant for training\n",
        "modelGo     = createResNetV1()  # This is used for final testing\n",
        "\n",
        "model.summary()                                                                 # Step 7"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Inpt_conv (Conv2D)              (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Inpt_bn (BatchNormalization)    (None, 32, 32, 16)   64          Inpt_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Inpt_relu (Activation)          (None, 32, 32, 16)   0           Inpt_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Inpt_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk1_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_Blk1_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk1_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk1_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_add (Add)             (None, 32, 32, 16)   0           Inpt_relu[0][0]                  \n",
            "                                                                 Stg1_Blk1_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk1_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk1_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk2_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_Blk2_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk2_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk2_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_add (Add)             (None, 32, 32, 16)   0           Stg1_Blk1_relu[0][0]             \n",
            "                                                                 Stg1_Blk2_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk2_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk2_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_Res1_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_Res1_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk3_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_Res1_relu (Activation (None, 32, 32, 16)   0           Stg1_Blk3_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_Res2_conv (Conv2D)    (None, 32, 32, 16)   2320        Stg1_Blk3_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_Res2_bn (BatchNormali (None, 32, 32, 16)   64          Stg1_Blk3_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_add (Add)             (None, 32, 32, 16)   0           Stg1_Blk2_relu[0][0]             \n",
            "                                                                 Stg1_Blk3_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg1_Blk3_relu (Activation)     (None, 32, 32, 16)   0           Stg1_Blk3_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_Res1_conv (Conv2D)    (None, 16, 16, 32)   4640        Stg1_Blk3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk1_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_Blk1_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk1_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_lin_conv (Conv2D)     (None, 16, 16, 32)   544         Stg1_Blk3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk1_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk1_lin_conv[0][0]         \n",
            "                                                                 Stg2_Blk1_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk1_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk1_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_Res1_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk2_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_Blk2_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk2_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk2_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk1_relu[0][0]             \n",
            "                                                                 Stg2_Blk2_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk2_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk2_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_Res1_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_Res1_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk3_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_Res1_relu (Activation (None, 16, 16, 32)   0           Stg2_Blk3_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_Res2_conv (Conv2D)    (None, 16, 16, 32)   9248        Stg2_Blk3_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_Res2_bn (BatchNormali (None, 16, 16, 32)   128         Stg2_Blk3_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_add (Add)             (None, 16, 16, 32)   0           Stg2_Blk2_relu[0][0]             \n",
            "                                                                 Stg2_Blk3_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg2_Blk3_relu (Activation)     (None, 16, 16, 32)   0           Stg2_Blk3_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_Res1_conv (Conv2D)    (None, 8, 8, 64)     18496       Stg2_Blk3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk1_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_Blk1_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk1_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_lin_conv (Conv2D)     (None, 8, 8, 64)     2112        Stg2_Blk3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk1_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk1_lin_conv[0][0]         \n",
            "                                                                 Stg3_Blk1_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk1_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk1_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_Res1_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk1_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk2_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_Blk2_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk2_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk2_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk1_relu[0][0]             \n",
            "                                                                 Stg3_Blk2_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk2_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk2_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_Res1_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk2_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_Res1_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk3_Res1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_Res1_relu (Activation (None, 8, 8, 64)     0           Stg3_Blk3_Res1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_Res2_conv (Conv2D)    (None, 8, 8, 64)     36928       Stg3_Blk3_Res1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_Res2_bn (BatchNormali (None, 8, 8, 64)     256         Stg3_Blk3_Res2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_add (Add)             (None, 8, 8, 64)     0           Stg3_Blk2_relu[0][0]             \n",
            "                                                                 Stg3_Blk3_Res2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Stg3_Blk3_relu (Activation)     (None, 8, 8, 64)     0           Stg3_Blk3_add[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "AvgPool (AveragePooling2D)      (None, 1, 1, 64)     0           Stg3_Blk3_relu[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           AvgPool[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlquJEaFZxV9"
      },
      "source": [
        "## **7. Create the callbacks to be applied during training**\n",
        "---\n",
        "* Step 1: Create a callback to save the model from an epoch when validation accuracy is the highest\n",
        "* Step 2: Create a callback to save the training loss, training accuracy, validation loss and validation accuracy of each epoch into a csv file\n",
        "* Step 3: Put the two callback objects into a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-a1LSCbahKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d238f5e5-824e-4241-ea33-3cbfa6897cba"
      },
      "source": [
        "                                                                                # Step 1\n",
        "def lrSchedule(epoch):\n",
        "    lr  = 1e-3\n",
        "    \n",
        "    if epoch > 160:\n",
        "        lr  *= 0.5e-3        \n",
        "    elif epoch > 140:\n",
        "        lr  *= 1e-3       \n",
        "    elif epoch > 120:\n",
        "        lr  *= 1e-2     \n",
        "    elif epoch > 80:\n",
        "        lr  *= 1e-1\n",
        "        \n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "LRScheduler     = LearningRateScheduler(lrSchedule)\n",
        "\n",
        "                                                                                # Step 2\n",
        "folderpath      = '/content/gdrive/My Drive/iss/prumls/colab/'\n",
        "filepath        = folderpath + modelname + \".hdf5\"\n",
        "checkpoint      = ModelCheckpoint(filepath, \n",
        "                                  monitor='val_accuracy', \n",
        "                                  verbose=0, \n",
        "                                  save_best_only=True, \n",
        "                                  mode='max')\n",
        "\n",
        "csv_logger      = CSVLogger(folderpath+modelname +'.csv')                       # Step 2\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "callbacks_list  = [checkpoint,csv_logger,LRScheduler]                           # Step 3\n",
        "\n",
        "print(\"Callbacks created:\")\n",
        "print(callbacks_list[0])\n",
        "print(callbacks_list[1])\n",
        "print(callbacks_list[2])\n",
        "print('')\n",
        "print(\"Path to model:\", filepath)\n",
        "print(\"Path to log:  \", folderpath+modelname+'.csv')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Callbacks created:\n",
            "<tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f51502c1c10>\n",
            "<tensorflow.python.keras.callbacks.CSVLogger object at 0x7f51502c1f10>\n",
            "<tensorflow.python.keras.callbacks.LearningRateScheduler object at 0x7f51502c1550>\n",
            "\n",
            "Path to model: /content/gdrive/My Drive/iss/prumls/colab/cifar10ResV1Cfg5.hdf5\n",
            "Path to log:   /content/gdrive/My Drive/iss/prumls/colab/cifar10ResV1Cfg5.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mKgjQsmfOBz"
      },
      "source": [
        "## **8. Train the deep learning model with image augmentation (to be completed)**\n",
        "___\n",
        "* Step 1: Create the image data generator (for image augmentation)\n",
        "* Step 2: Train the model with generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23lUNwpGfV0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00c6589-84c7-4012-e91f-aeaac2a1dee0"
      },
      "source": [
        "                                                                                # Step 1\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            rotation_range=20,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                                                                # Step 2\n",
        "\n",
        "model.fit_generator(datagen.flow(trDat, trLbl, batch_size=64),\n",
        "                    validation_data=(tsDat, tsLbl),\n",
        "                    epochs=200, \n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=len(trDat)/64,\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 67s 42ms/step - loss: 1.6500 - accuracy: 0.4549 - val_loss: 2.3257 - val_accuracy: 0.4353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 1.3028 - accuracy: 0.5847 - val_loss: 2.6411 - val_accuracy: 0.3653\n",
            "Epoch 3/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 1.1331 - accuracy: 0.6513 - val_loss: 1.7777 - val_accuracy: 0.5190\n",
            "Epoch 4/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 1.0196 - accuracy: 0.6948 - val_loss: 1.1603 - val_accuracy: 0.6645\n",
            "Epoch 5/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.9397 - accuracy: 0.7239 - val_loss: 1.2028 - val_accuracy: 0.6647\n",
            "Epoch 6/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8862 - accuracy: 0.7436 - val_loss: 1.1363 - val_accuracy: 0.6932\n",
            "Epoch 7/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.8443 - accuracy: 0.7606 - val_loss: 1.0703 - val_accuracy: 0.7003\n",
            "Epoch 8/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.8100 - accuracy: 0.7719 - val_loss: 0.9483 - val_accuracy: 0.7321\n",
            "Epoch 9/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.7795 - accuracy: 0.7805 - val_loss: 1.0419 - val_accuracy: 0.7168\n",
            "Epoch 10/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.7556 - accuracy: 0.7919 - val_loss: 0.7642 - val_accuracy: 0.7862\n",
            "Epoch 11/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.7340 - accuracy: 0.7992 - val_loss: 0.9758 - val_accuracy: 0.7322\n",
            "Epoch 12/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.7162 - accuracy: 0.8064 - val_loss: 0.8787 - val_accuracy: 0.7593\n",
            "Epoch 13/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.6996 - accuracy: 0.8123 - val_loss: 0.8400 - val_accuracy: 0.7783\n",
            "Epoch 14/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.6831 - accuracy: 0.8188 - val_loss: 1.0176 - val_accuracy: 0.7364\n",
            "Epoch 15/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.6784 - accuracy: 0.8219 - val_loss: 0.8503 - val_accuracy: 0.7756\n",
            "Epoch 16/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.6578 - accuracy: 0.8295 - val_loss: 0.8983 - val_accuracy: 0.7700\n",
            "Epoch 17/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.6547 - accuracy: 0.8307 - val_loss: 0.8833 - val_accuracy: 0.7673\n",
            "Epoch 18/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.6414 - accuracy: 0.8341 - val_loss: 0.7552 - val_accuracy: 0.8084\n",
            "Epoch 19/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.6338 - accuracy: 0.8378 - val_loss: 0.7741 - val_accuracy: 0.8056\n",
            "Epoch 20/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.6270 - accuracy: 0.8402 - val_loss: 1.0723 - val_accuracy: 0.7354\n",
            "Epoch 21/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.6175 - accuracy: 0.8444 - val_loss: 0.7020 - val_accuracy: 0.8164\n",
            "Epoch 22/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.6086 - accuracy: 0.8481 - val_loss: 0.7752 - val_accuracy: 0.8092\n",
            "Epoch 23/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.6074 - accuracy: 0.8479 - val_loss: 0.8682 - val_accuracy: 0.7813\n",
            "Epoch 24/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5949 - accuracy: 0.8518 - val_loss: 0.7414 - val_accuracy: 0.8235\n",
            "Epoch 25/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5933 - accuracy: 0.8531 - val_loss: 0.7243 - val_accuracy: 0.8199\n",
            "Epoch 26/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5884 - accuracy: 0.8540 - val_loss: 0.6196 - val_accuracy: 0.8495\n",
            "Epoch 27/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5805 - accuracy: 0.8589 - val_loss: 0.9366 - val_accuracy: 0.7793\n",
            "Epoch 28/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5772 - accuracy: 0.8599 - val_loss: 0.6759 - val_accuracy: 0.8317\n",
            "Epoch 29/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5699 - accuracy: 0.8621 - val_loss: 0.7381 - val_accuracy: 0.8244\n",
            "Epoch 30/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5711 - accuracy: 0.8616 - val_loss: 0.8202 - val_accuracy: 0.7954\n",
            "Epoch 31/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5649 - accuracy: 0.8626 - val_loss: 0.6657 - val_accuracy: 0.8334\n",
            "Epoch 32/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5661 - accuracy: 0.8640 - val_loss: 0.7222 - val_accuracy: 0.8247\n",
            "Epoch 33/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5559 - accuracy: 0.8665 - val_loss: 0.6185 - val_accuracy: 0.8517\n",
            "Epoch 34/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5543 - accuracy: 0.8675 - val_loss: 0.7391 - val_accuracy: 0.8165\n",
            "Epoch 35/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5547 - accuracy: 0.8686 - val_loss: 0.7876 - val_accuracy: 0.8046\n",
            "Epoch 36/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5521 - accuracy: 0.8693 - val_loss: 0.7153 - val_accuracy: 0.8310\n",
            "Epoch 37/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5442 - accuracy: 0.8716 - val_loss: 0.6828 - val_accuracy: 0.8369\n",
            "Epoch 38/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5437 - accuracy: 0.8740 - val_loss: 0.6917 - val_accuracy: 0.8369\n",
            "Epoch 39/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5473 - accuracy: 0.8727 - val_loss: 0.7149 - val_accuracy: 0.8249\n",
            "Epoch 40/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5356 - accuracy: 0.8767 - val_loss: 0.8333 - val_accuracy: 0.7925\n",
            "Epoch 41/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5337 - accuracy: 0.8775 - val_loss: 0.7582 - val_accuracy: 0.8110\n",
            "Epoch 42/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.5296 - accuracy: 0.8778 - val_loss: 0.6532 - val_accuracy: 0.8446\n",
            "Epoch 43/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5309 - accuracy: 0.8782 - val_loss: 0.7318 - val_accuracy: 0.8266\n",
            "Epoch 44/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5282 - accuracy: 0.8796 - val_loss: 0.8261 - val_accuracy: 0.7955\n",
            "Epoch 45/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5300 - accuracy: 0.8786 - val_loss: 0.6210 - val_accuracy: 0.8535\n",
            "Epoch 46/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5268 - accuracy: 0.8794 - val_loss: 0.6949 - val_accuracy: 0.8333\n",
            "Epoch 47/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5228 - accuracy: 0.8810 - val_loss: 0.7632 - val_accuracy: 0.8216\n",
            "Epoch 48/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5173 - accuracy: 0.8819 - val_loss: 0.8153 - val_accuracy: 0.8032\n",
            "Epoch 49/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5213 - accuracy: 0.8817 - val_loss: 0.7079 - val_accuracy: 0.8287\n",
            "Epoch 50/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5184 - accuracy: 0.8821 - val_loss: 0.6550 - val_accuracy: 0.8490\n",
            "Epoch 51/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5125 - accuracy: 0.8843 - val_loss: 0.6613 - val_accuracy: 0.8444\n",
            "Epoch 52/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5152 - accuracy: 0.8843 - val_loss: 0.5845 - val_accuracy: 0.8649\n",
            "Epoch 53/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5151 - accuracy: 0.8834 - val_loss: 0.6024 - val_accuracy: 0.8628\n",
            "Epoch 54/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5129 - accuracy: 0.8845 - val_loss: 0.7326 - val_accuracy: 0.8237\n",
            "Epoch 55/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5160 - accuracy: 0.8823 - val_loss: 0.6439 - val_accuracy: 0.8478\n",
            "Epoch 56/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5137 - accuracy: 0.8847 - val_loss: 0.6171 - val_accuracy: 0.8609\n",
            "Epoch 57/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5097 - accuracy: 0.8869 - val_loss: 0.7202 - val_accuracy: 0.8334\n",
            "Epoch 58/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5126 - accuracy: 0.8857 - val_loss: 0.7307 - val_accuracy: 0.8318\n",
            "Epoch 59/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5051 - accuracy: 0.8880 - val_loss: 0.6511 - val_accuracy: 0.8432\n",
            "Epoch 60/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5043 - accuracy: 0.8879 - val_loss: 0.6851 - val_accuracy: 0.8453\n",
            "Epoch 61/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5051 - accuracy: 0.8892 - val_loss: 0.6996 - val_accuracy: 0.8352\n",
            "Epoch 62/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4998 - accuracy: 0.8884 - val_loss: 0.6472 - val_accuracy: 0.8508\n",
            "Epoch 63/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5017 - accuracy: 0.8895 - val_loss: 0.7532 - val_accuracy: 0.8237\n",
            "Epoch 64/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4975 - accuracy: 0.8900 - val_loss: 0.6776 - val_accuracy: 0.8410\n",
            "Epoch 65/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4977 - accuracy: 0.8903 - val_loss: 0.7764 - val_accuracy: 0.8111\n",
            "Epoch 66/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5007 - accuracy: 0.8897 - val_loss: 0.7233 - val_accuracy: 0.8320\n",
            "Epoch 67/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4967 - accuracy: 0.8897 - val_loss: 0.6493 - val_accuracy: 0.8490\n",
            "Epoch 68/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4989 - accuracy: 0.8905 - val_loss: 0.6298 - val_accuracy: 0.8567\n",
            "Epoch 69/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4997 - accuracy: 0.8910 - val_loss: 0.7434 - val_accuracy: 0.8194\n",
            "Epoch 70/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4940 - accuracy: 0.8929 - val_loss: 0.8726 - val_accuracy: 0.8011\n",
            "Epoch 71/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4939 - accuracy: 0.8911 - val_loss: 0.7626 - val_accuracy: 0.8220\n",
            "Epoch 72/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4875 - accuracy: 0.8954 - val_loss: 0.5736 - val_accuracy: 0.8709\n",
            "Epoch 73/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.4897 - accuracy: 0.8937 - val_loss: 0.6552 - val_accuracy: 0.8531\n",
            "Epoch 74/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4904 - accuracy: 0.8934 - val_loss: 0.8106 - val_accuracy: 0.8149\n",
            "Epoch 75/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.4895 - accuracy: 0.8934 - val_loss: 0.7545 - val_accuracy: 0.8303\n",
            "Epoch 76/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4835 - accuracy: 0.8960 - val_loss: 0.6916 - val_accuracy: 0.8416\n",
            "Epoch 77/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.4883 - accuracy: 0.8938 - val_loss: 0.6987 - val_accuracy: 0.8408\n",
            "Epoch 78/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4898 - accuracy: 0.8941 - val_loss: 0.6334 - val_accuracy: 0.8582\n",
            "Epoch 79/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4845 - accuracy: 0.8954 - val_loss: 0.8743 - val_accuracy: 0.8070\n",
            "Epoch 80/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4891 - accuracy: 0.8941 - val_loss: 0.6478 - val_accuracy: 0.8545\n",
            "Epoch 81/200\n",
            "Learning rate:  0.001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.4882 - accuracy: 0.8951 - val_loss: 0.8732 - val_accuracy: 0.8044\n",
            "Epoch 82/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4148 - accuracy: 0.9206 - val_loss: 0.4960 - val_accuracy: 0.8984\n",
            "Epoch 83/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3860 - accuracy: 0.9300 - val_loss: 0.4943 - val_accuracy: 0.8984\n",
            "Epoch 84/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3748 - accuracy: 0.9339 - val_loss: 0.4825 - val_accuracy: 0.8997\n",
            "Epoch 85/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.3633 - accuracy: 0.9361 - val_loss: 0.4698 - val_accuracy: 0.9063\n",
            "Epoch 86/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3548 - accuracy: 0.9393 - val_loss: 0.4741 - val_accuracy: 0.9045\n",
            "Epoch 87/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.3464 - accuracy: 0.9412 - val_loss: 0.4756 - val_accuracy: 0.9017\n",
            "Epoch 88/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3464 - accuracy: 0.9406 - val_loss: 0.4757 - val_accuracy: 0.9027\n",
            "Epoch 89/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3372 - accuracy: 0.9413 - val_loss: 0.4865 - val_accuracy: 0.9005\n",
            "Epoch 90/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3333 - accuracy: 0.9432 - val_loss: 0.4645 - val_accuracy: 0.9045\n",
            "Epoch 91/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3249 - accuracy: 0.9440 - val_loss: 0.4840 - val_accuracy: 0.8964\n",
            "Epoch 92/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3237 - accuracy: 0.9455 - val_loss: 0.4606 - val_accuracy: 0.9047\n",
            "Epoch 93/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3183 - accuracy: 0.9471 - val_loss: 0.4762 - val_accuracy: 0.9010\n",
            "Epoch 94/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3149 - accuracy: 0.9469 - val_loss: 0.4649 - val_accuracy: 0.9063\n",
            "Epoch 95/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.3146 - accuracy: 0.9467 - val_loss: 0.4840 - val_accuracy: 0.9004\n",
            "Epoch 96/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.3084 - accuracy: 0.9490 - val_loss: 0.4584 - val_accuracy: 0.9058\n",
            "Epoch 97/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.3041 - accuracy: 0.9497 - val_loss: 0.4678 - val_accuracy: 0.9025\n",
            "Epoch 98/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.3068 - accuracy: 0.9480 - val_loss: 0.4690 - val_accuracy: 0.9019\n",
            "Epoch 99/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2977 - accuracy: 0.9507 - val_loss: 0.4586 - val_accuracy: 0.9044\n",
            "Epoch 100/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.3000 - accuracy: 0.9492 - val_loss: 0.4595 - val_accuracy: 0.9021\n",
            "Epoch 101/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2948 - accuracy: 0.9520 - val_loss: 0.4575 - val_accuracy: 0.9042\n",
            "Epoch 102/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2920 - accuracy: 0.9512 - val_loss: 0.4522 - val_accuracy: 0.9055\n",
            "Epoch 103/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2905 - accuracy: 0.9520 - val_loss: 0.4586 - val_accuracy: 0.9044\n",
            "Epoch 104/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2837 - accuracy: 0.9539 - val_loss: 0.4593 - val_accuracy: 0.9043\n",
            "Epoch 105/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2866 - accuracy: 0.9519 - val_loss: 0.4587 - val_accuracy: 0.9035\n",
            "Epoch 106/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2841 - accuracy: 0.9530 - val_loss: 0.4746 - val_accuracy: 0.9015\n",
            "Epoch 107/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2788 - accuracy: 0.9544 - val_loss: 0.4566 - val_accuracy: 0.9066\n",
            "Epoch 108/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2759 - accuracy: 0.9541 - val_loss: 0.4547 - val_accuracy: 0.9048\n",
            "Epoch 109/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2747 - accuracy: 0.9557 - val_loss: 0.4603 - val_accuracy: 0.9028\n",
            "Epoch 110/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2729 - accuracy: 0.9544 - val_loss: 0.4520 - val_accuracy: 0.9071\n",
            "Epoch 111/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2710 - accuracy: 0.9542 - val_loss: 0.4580 - val_accuracy: 0.9019\n",
            "Epoch 112/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2690 - accuracy: 0.9558 - val_loss: 0.4534 - val_accuracy: 0.9051\n",
            "Epoch 113/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2645 - accuracy: 0.9567 - val_loss: 0.4437 - val_accuracy: 0.9087\n",
            "Epoch 114/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2661 - accuracy: 0.9560 - val_loss: 0.4498 - val_accuracy: 0.9056\n",
            "Epoch 115/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2663 - accuracy: 0.9561 - val_loss: 0.4487 - val_accuracy: 0.9052\n",
            "Epoch 116/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2613 - accuracy: 0.9567 - val_loss: 0.4741 - val_accuracy: 0.9015\n",
            "Epoch 117/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2587 - accuracy: 0.9567 - val_loss: 0.4477 - val_accuracy: 0.9071\n",
            "Epoch 118/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2562 - accuracy: 0.9586 - val_loss: 0.4712 - val_accuracy: 0.8981\n",
            "Epoch 119/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2531 - accuracy: 0.9590 - val_loss: 0.4544 - val_accuracy: 0.9066\n",
            "Epoch 120/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2508 - accuracy: 0.9585 - val_loss: 0.4669 - val_accuracy: 0.9024\n",
            "Epoch 121/200\n",
            "Learning rate:  0.0001\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2517 - accuracy: 0.9593 - val_loss: 0.4429 - val_accuracy: 0.9055\n",
            "Epoch 122/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2435 - accuracy: 0.9614 - val_loss: 0.4403 - val_accuracy: 0.9073\n",
            "Epoch 123/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2380 - accuracy: 0.9636 - val_loss: 0.4390 - val_accuracy: 0.9096\n",
            "Epoch 124/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2379 - accuracy: 0.9629 - val_loss: 0.4357 - val_accuracy: 0.9097\n",
            "Epoch 125/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2384 - accuracy: 0.9635 - val_loss: 0.4364 - val_accuracy: 0.9084\n",
            "Epoch 126/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2393 - accuracy: 0.9629 - val_loss: 0.4384 - val_accuracy: 0.9080\n",
            "Epoch 127/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2373 - accuracy: 0.9645 - val_loss: 0.4384 - val_accuracy: 0.9076\n",
            "Epoch 128/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.2370 - accuracy: 0.9642 - val_loss: 0.4354 - val_accuracy: 0.9078\n",
            "Epoch 129/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2351 - accuracy: 0.9647 - val_loss: 0.4363 - val_accuracy: 0.9094\n",
            "Epoch 130/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.2345 - accuracy: 0.9644 - val_loss: 0.4370 - val_accuracy: 0.9098\n",
            "Epoch 131/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2340 - accuracy: 0.9643 - val_loss: 0.4359 - val_accuracy: 0.9093\n",
            "Epoch 132/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2357 - accuracy: 0.9649 - val_loss: 0.4382 - val_accuracy: 0.9090\n",
            "Epoch 133/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.2338 - accuracy: 0.9647 - val_loss: 0.4357 - val_accuracy: 0.9102\n",
            "Epoch 134/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2335 - accuracy: 0.9645 - val_loss: 0.4438 - val_accuracy: 0.9078\n",
            "Epoch 135/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.2331 - accuracy: 0.9659 - val_loss: 0.4392 - val_accuracy: 0.9083\n",
            "Epoch 136/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2334 - accuracy: 0.9649 - val_loss: 0.4377 - val_accuracy: 0.9100\n",
            "Epoch 137/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.2330 - accuracy: 0.9651 - val_loss: 0.4399 - val_accuracy: 0.9091\n",
            "Epoch 138/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2311 - accuracy: 0.9656 - val_loss: 0.4381 - val_accuracy: 0.9094\n",
            "Epoch 139/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2326 - accuracy: 0.9649 - val_loss: 0.4363 - val_accuracy: 0.9091\n",
            "Epoch 140/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2328 - accuracy: 0.9648 - val_loss: 0.4374 - val_accuracy: 0.9094\n",
            "Epoch 141/200\n",
            "Learning rate:  1e-05\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2343 - accuracy: 0.9648 - val_loss: 0.4340 - val_accuracy: 0.9107\n",
            "Epoch 142/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2312 - accuracy: 0.9656 - val_loss: 0.4386 - val_accuracy: 0.9088\n",
            "Epoch 143/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2296 - accuracy: 0.9658 - val_loss: 0.4369 - val_accuracy: 0.9089\n",
            "Epoch 144/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2311 - accuracy: 0.9661 - val_loss: 0.4363 - val_accuracy: 0.9093\n",
            "Epoch 145/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2309 - accuracy: 0.9667 - val_loss: 0.4368 - val_accuracy: 0.9093\n",
            "Epoch 146/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2300 - accuracy: 0.9668 - val_loss: 0.4373 - val_accuracy: 0.9096\n",
            "Epoch 147/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2291 - accuracy: 0.9666 - val_loss: 0.4359 - val_accuracy: 0.9099\n",
            "Epoch 148/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2312 - accuracy: 0.9656 - val_loss: 0.4353 - val_accuracy: 0.9096\n",
            "Epoch 149/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2297 - accuracy: 0.9655 - val_loss: 0.4361 - val_accuracy: 0.9102\n",
            "Epoch 150/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2292 - accuracy: 0.9664 - val_loss: 0.4357 - val_accuracy: 0.9099\n",
            "Epoch 151/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2311 - accuracy: 0.9660 - val_loss: 0.4357 - val_accuracy: 0.9101\n",
            "Epoch 152/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2294 - accuracy: 0.9667 - val_loss: 0.4377 - val_accuracy: 0.9092\n",
            "Epoch 153/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2295 - accuracy: 0.9668 - val_loss: 0.4370 - val_accuracy: 0.9094\n",
            "Epoch 154/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2267 - accuracy: 0.9673 - val_loss: 0.4367 - val_accuracy: 0.9092\n",
            "Epoch 155/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2319 - accuracy: 0.9650 - val_loss: 0.4352 - val_accuracy: 0.9099\n",
            "Epoch 156/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2324 - accuracy: 0.9654 - val_loss: 0.4372 - val_accuracy: 0.9084\n",
            "Epoch 157/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2303 - accuracy: 0.9654 - val_loss: 0.4359 - val_accuracy: 0.9096\n",
            "Epoch 158/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2287 - accuracy: 0.9661 - val_loss: 0.4370 - val_accuracy: 0.9092\n",
            "Epoch 159/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2296 - accuracy: 0.9665 - val_loss: 0.4384 - val_accuracy: 0.9094\n",
            "Epoch 160/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2302 - accuracy: 0.9656 - val_loss: 0.4384 - val_accuracy: 0.9088\n",
            "Epoch 161/200\n",
            "Learning rate:  1e-06\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2317 - accuracy: 0.9651 - val_loss: 0.4378 - val_accuracy: 0.9097\n",
            "Epoch 162/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2282 - accuracy: 0.9677 - val_loss: 0.4374 - val_accuracy: 0.9091\n",
            "Epoch 163/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2291 - accuracy: 0.9663 - val_loss: 0.4349 - val_accuracy: 0.9096\n",
            "Epoch 164/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2282 - accuracy: 0.9662 - val_loss: 0.4360 - val_accuracy: 0.9093\n",
            "Epoch 165/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2301 - accuracy: 0.9661 - val_loss: 0.4381 - val_accuracy: 0.9090\n",
            "Epoch 166/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2291 - accuracy: 0.9669 - val_loss: 0.4381 - val_accuracy: 0.9086\n",
            "Epoch 167/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.2266 - accuracy: 0.9679 - val_loss: 0.4377 - val_accuracy: 0.9088\n",
            "Epoch 168/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2270 - accuracy: 0.9672 - val_loss: 0.4363 - val_accuracy: 0.9090\n",
            "Epoch 169/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2278 - accuracy: 0.9656 - val_loss: 0.4361 - val_accuracy: 0.9093\n",
            "Epoch 170/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2294 - accuracy: 0.9664 - val_loss: 0.4372 - val_accuracy: 0.9090\n",
            "Epoch 171/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2289 - accuracy: 0.9670 - val_loss: 0.4365 - val_accuracy: 0.9095\n",
            "Epoch 172/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2289 - accuracy: 0.9661 - val_loss: 0.4345 - val_accuracy: 0.9099\n",
            "Epoch 173/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2283 - accuracy: 0.9672 - val_loss: 0.4378 - val_accuracy: 0.9089\n",
            "Epoch 174/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2303 - accuracy: 0.9666 - val_loss: 0.4373 - val_accuracy: 0.9091\n",
            "Epoch 175/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2295 - accuracy: 0.9665 - val_loss: 0.4385 - val_accuracy: 0.9091\n",
            "Epoch 176/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.2288 - accuracy: 0.9665 - val_loss: 0.4376 - val_accuracy: 0.9101\n",
            "Epoch 177/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2276 - accuracy: 0.9668 - val_loss: 0.4377 - val_accuracy: 0.9087\n",
            "Epoch 178/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2295 - accuracy: 0.9665 - val_loss: 0.4358 - val_accuracy: 0.9094\n",
            "Epoch 179/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2290 - accuracy: 0.9661 - val_loss: 0.4388 - val_accuracy: 0.9086\n",
            "Epoch 180/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2277 - accuracy: 0.9670 - val_loss: 0.4370 - val_accuracy: 0.9085\n",
            "Epoch 181/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2296 - accuracy: 0.9663 - val_loss: 0.4381 - val_accuracy: 0.9088\n",
            "Epoch 182/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2265 - accuracy: 0.9671 - val_loss: 0.4366 - val_accuracy: 0.9090\n",
            "Epoch 183/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2302 - accuracy: 0.9654 - val_loss: 0.4391 - val_accuracy: 0.9084\n",
            "Epoch 184/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2282 - accuracy: 0.9659 - val_loss: 0.4377 - val_accuracy: 0.9082\n",
            "Epoch 185/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2275 - accuracy: 0.9667 - val_loss: 0.4356 - val_accuracy: 0.9084\n",
            "Epoch 186/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2289 - accuracy: 0.9671 - val_loss: 0.4383 - val_accuracy: 0.9096\n",
            "Epoch 187/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2287 - accuracy: 0.9661 - val_loss: 0.4383 - val_accuracy: 0.9089\n",
            "Epoch 188/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.2296 - accuracy: 0.9658 - val_loss: 0.4372 - val_accuracy: 0.9092\n",
            "Epoch 189/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2285 - accuracy: 0.9669 - val_loss: 0.4367 - val_accuracy: 0.9090\n",
            "Epoch 190/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2285 - accuracy: 0.9662 - val_loss: 0.4365 - val_accuracy: 0.9089\n",
            "Epoch 191/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2264 - accuracy: 0.9669 - val_loss: 0.4376 - val_accuracy: 0.9085\n",
            "Epoch 192/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2298 - accuracy: 0.9656 - val_loss: 0.4378 - val_accuracy: 0.9096\n",
            "Epoch 193/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2273 - accuracy: 0.9667 - val_loss: 0.4364 - val_accuracy: 0.9087\n",
            "Epoch 194/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2294 - accuracy: 0.9663 - val_loss: 0.4357 - val_accuracy: 0.9092\n",
            "Epoch 195/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2266 - accuracy: 0.9671 - val_loss: 0.4381 - val_accuracy: 0.9087\n",
            "Epoch 196/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2277 - accuracy: 0.9670 - val_loss: 0.4374 - val_accuracy: 0.9088\n",
            "Epoch 197/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2297 - accuracy: 0.9664 - val_loss: 0.4378 - val_accuracy: 0.9081\n",
            "Epoch 198/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2293 - accuracy: 0.9656 - val_loss: 0.4374 - val_accuracy: 0.9091\n",
            "Epoch 199/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.2280 - accuracy: 0.9667 - val_loss: 0.4396 - val_accuracy: 0.9087\n",
            "Epoch 200/200\n",
            "Learning rate:  5e-07\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.2299 - accuracy: 0.9663 - val_loss: 0.4358 - val_accuracy: 0.9088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f51502aa890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TevfJTd-s0nk"
      },
      "source": [
        "## **9. Validate the deep learning model**\n",
        "---\n",
        "* Step 1: Load the trained weights and compile the model\n",
        "* Step 2: Make prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sVtWmcVtiV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f246bbd-46d4-43d2-b483-dd19652cfb32"
      },
      "source": [
        "                                                                                # Step 1\n",
        "modelGo.load_weights(filepath)\n",
        "modelGo.compile(loss='categorical_crossentropy', \n",
        "                optimizer=optmz, \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "predicts    = modelGo.predict(tsDat)                                            # Step 2\n",
        "print(\"Prediction completes.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction completes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOCUljp5qq4"
      },
      "source": [
        "## **10. Report classification metrics**\n",
        "---\n",
        "* Step 1: Setup the label\n",
        "* Step 2: Convert label from one-hot to integer\n",
        "* Step 3: Calculate the accuracy score\n",
        "* Step 4: Generate classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tI4hBmk5uRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299ef453-e348-4954-cd23-0ff97e2c1776"
      },
      "source": [
        "                                                                                # Step 1\n",
        "labelname   = ['airplane',          # The label for reporting metrics\n",
        "               'automobile',\n",
        "               'bird',\n",
        "               'cat',\n",
        "               'deer',\n",
        "               'dog',\n",
        "               'frog',\n",
        "               'horse',\n",
        "               'ship',\n",
        "               'truck']\n",
        "                                                                                # Step 2\n",
        "predout     = np.argmax(predicts,axis=1)\n",
        "testout     = np.argmax(tsLbl,axis=1)\n",
        "\n",
        "testScores  = metrics.accuracy_score(testout,predout)                           # Step 3\n",
        "\n",
        "                                                                                # Step 4\n",
        "print(\"Best accuracy (on testing dataset): %.2f%%\" % (testScores*100))\n",
        "print(metrics.classification_report(testout,\n",
        "                                    predout,\n",
        "                                    target_names=labelname,\n",
        "                                    digits=4))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy (on testing dataset): 91.07%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane     0.9269    0.9260    0.9265      1000\n",
            "  automobile     0.9322    0.9620    0.9469      1000\n",
            "        bird     0.8919    0.8830    0.8874      1000\n",
            "         cat     0.8415    0.7910    0.8155      1000\n",
            "        deer     0.9119    0.9210    0.9164      1000\n",
            "         dog     0.8978    0.8170    0.8555      1000\n",
            "        frog     0.8949    0.9620    0.9272      1000\n",
            "       horse     0.9401    0.9420    0.9411      1000\n",
            "        ship     0.9495    0.9590    0.9542      1000\n",
            "       truck     0.9147    0.9440    0.9291      1000\n",
            "\n",
            "    accuracy                         0.9107     10000\n",
            "   macro avg     0.9101    0.9107    0.9100     10000\n",
            "weighted avg     0.9101    0.9107    0.9100     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEK_4UXN6IVa"
      },
      "source": [
        "## **11. Print confusion matrix**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCBJCYp26L1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61d59c9-d6f9-47b6-f449-11dc3732599d"
      },
      "source": [
        "confusion   = metrics.confusion_matrix(testout,predout)\n",
        "print(confusion)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[926  13  18   1   1   1   2   4  22  12]\n",
            " [  1 962   0   1   0   0   0   0   2  34]\n",
            " [ 14   2 883  22  18  13  28   8   6   6]\n",
            " [ 12   7  35 791  25  59  41  13   7  10]\n",
            " [  3   1  18  14 921   7  21  13   1   1]\n",
            " [  7   4  14  91  22 817  17  21   2   5]\n",
            " [  6   0  13   7   5   2 962   1   0   4]\n",
            " [  5   0   6  11  17  11   4 942   2   2]\n",
            " [ 16   7   2   2   0   0   0   0 959  14]\n",
            " [  9  36   1   0   1   0   0   0   9 944]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QMIDPD46UGT"
      },
      "source": [
        "## **12. Plot curves on validation loss and accuracy**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr2ZbvUi6YHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "6e01f3db-eed8-43c3-d83f-b140950e065b"
      },
      "source": [
        "records     = pd.read_csv(folderpath+modelname +'.csv')\n",
        "plt.figure()\n",
        "plt.subplot(211)\n",
        "plt.plot(records['val_loss'], label=\"validation\")\n",
        "plt.plot(records['loss'],label=\"training\")\n",
        "plt.yticks([0.00,0.50,1.00,1.50])\n",
        "plt.title('Loss value',fontsize=12)\n",
        "\n",
        "ax          = plt.gca()\n",
        "ax.set_xticklabels([])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(records['val_accuracy'],label=\"validation\")\n",
        "plt.plot(records['accuracy'],label=\"training\")\n",
        "plt.yticks([0.5,0.6,0.7,0.8])\n",
        "plt.title('Accuracy',fontsize=12)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWoTz-bLug3X"
      },
      "source": [
        "## **13. Save the model plot**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz1YfuV1ujcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ff2149-aa56-410a-8d60-4d49f710e47b"
      },
      "source": [
        "plotpath  = folderpath+modelname+'_plot.png'\n",
        "plot_model(model, \n",
        "           to_file=plotpath, \n",
        "           show_shapes=True, \n",
        "           show_layer_names=False,\n",
        "           rankdir='TB')\n",
        "\n",
        "print(\"Path to plot:\", plotpath)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path to plot: /content/gdrive/My Drive/iss/prumls/colab/cifar10ResV1Cfg5_plot.png\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}